{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_idgCcuZdv0S",
        "colab_type": "text"
      },
      "source": [
        "# **Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO1kBOuDd2_r",
        "colab_type": "text"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "outputId": "f7e6d6a4-ee5c-41d3-d593-a1e75e8ac18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyV1MMm_O_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_data_X, Y_data, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRS393n_O_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoh02WT5wiLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx0sJsJDwiJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCu-tWhd_O_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# creating initial dataframe\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_train_df['New'] = labelencoder.fit_transform(y_train_df['Label'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_test_df['New'] = labelencoder.fit_transform(y_test_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5CHhcF_PAA",
        "colab_type": "code",
        "outputId": "0f1f8e43-5494-41dc-943f-2cab41f2946e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend as K\n",
        "img_rows, img_cols = X_train[0].shape\n",
        "\n",
        "\n",
        "# transform data set\n",
        "if K.common.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTmOEDcMtSQp",
        "colab_type": "text"
      },
      "source": [
        "# Othogonal Constraint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S2jnj2otWlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.constraints import Constraint\n",
        "from tensorflow.python.ops import math_ops, array_ops\n",
        "\n",
        "class TightFrame(Constraint):\n",
        "\n",
        "\n",
        "    def __init__(self, scale, num_passes=1):\n",
        "        self.scale = scale\n",
        "\n",
        "        if num_passes < 1:\n",
        "            raise ValueError(\"Number of passes cannot be non-positive! (got {})\".format(num_passes))\n",
        "        self.num_passes = num_passes\n",
        "\n",
        "\n",
        "    def __call__(self, w):\n",
        "        transpose_channels = (len(w.shape) == 4)\n",
        "\n",
        "        # Move channels_num to the front in order to make the dimensions correct for matmul\n",
        "        if transpose_channels:\n",
        "            w_reordered = array_ops.reshape(w, (-1, w.shape[0]))\n",
        "\n",
        "        else:\n",
        "            w_reordered = w\n",
        "\n",
        "        last = w_reordered\n",
        "        for i in range(self.num_passes):\n",
        "            temp1 = math_ops.matmul(last, last, transpose_a=True)\n",
        "            temp2 = (1 + self.scale) * w_reordered - self.scale * math_ops.matmul(w_reordered, temp1)\n",
        "\n",
        "            last = temp2\n",
        "\n",
        "        # Move channels_num to the back again\n",
        "        if transpose_channels:\n",
        "            return array_ops.reshape(last, w.shape)\n",
        "        else:\n",
        "            return last\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'scale': self.scale, 'num_passes': self.num_passes}\n",
        "\n",
        "\n",
        "# Alias\n",
        "tight_frame = TightFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4VciYzctsSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "outputId": "c703c897-e52c-4559-93e4-6f43adea5f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal', kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_constraint= tight_frame(0.0001),\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_parseval_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (68, 100,1)\n",
        "\n",
        "    parseval_16_2 = create_parseval_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.callbacks as callbacks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "BS = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "outputId": "077111d1-6084-4c55-af5a-6655cd264c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "parseval_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./68,\n",
        "                               height_shift_range=5./100,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4EpGTMG9jeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 60:\n",
        "        return 0.1\n",
        "    elif epoch < 120:\n",
        "        return 0.02\n",
        "    elif epoch < 160:\n",
        "        return 0.004\n",
        "    else:\n",
        "        return 0.0008\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bu78FGi9jhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0CbPY_24ns",
        "colab_type": "code",
        "outputId": "ead72055-bcce-4aa3-e141-93f1a3c15d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "hist = parseval_16_2.fit(generator.flow(X_train, to_categorical(y_train_df['New']), batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   validation_data=(X_test, to_categorical(y_test_df['New'])), callbacks = [lr_scheduler],\n",
        "                   validation_steps=X_test.shape[0] // BS,)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "29/29 [==============================] - 19s 655ms/step - loss: 1.7989 - acc: 0.3366 - val_loss: 1.7291 - val_acc: 0.3467 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 1.6557 - acc: 0.3595 - val_loss: 1.5943 - val_acc: 0.3690 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 16s 539ms/step - loss: 1.5626 - acc: 0.4124 - val_loss: 1.5009 - val_acc: 0.4240 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 1.4993 - acc: 0.4340 - val_loss: 1.4621 - val_acc: 0.4161 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 1.4429 - acc: 0.4470 - val_loss: 1.4017 - val_acc: 0.4722 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 1.3554 - acc: 0.4764 - val_loss: 1.3359 - val_acc: 0.5066 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 1.3240 - acc: 0.4953 - val_loss: 1.3162 - val_acc: 0.5093 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 1.2544 - acc: 0.5395 - val_loss: 1.3035 - val_acc: 0.5061 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 1.1862 - acc: 0.5668 - val_loss: 1.1643 - val_acc: 0.5802 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 1.1240 - acc: 0.5992 - val_loss: 1.1441 - val_acc: 0.5998 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 1.0884 - acc: 0.6067 - val_loss: 1.0729 - val_acc: 0.6125 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 1.0293 - acc: 0.6426 - val_loss: 1.0422 - val_acc: 0.6257 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 1.0006 - acc: 0.6421 - val_loss: 0.9982 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.9895 - acc: 0.6445 - val_loss: 0.9782 - val_acc: 0.6670 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.9491 - acc: 0.6637 - val_loss: 0.9868 - val_acc: 0.6739 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.9209 - acc: 0.6796 - val_loss: 1.0246 - val_acc: 0.6390 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.9466 - acc: 0.6699 - val_loss: 0.9529 - val_acc: 0.6681 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.8754 - acc: 0.6877 - val_loss: 0.9272 - val_acc: 0.6840 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.8360 - acc: 0.7126 - val_loss: 0.9328 - val_acc: 0.6829 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.8577 - acc: 0.6974 - val_loss: 0.9540 - val_acc: 0.6644 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 0.8167 - acc: 0.7231 - val_loss: 0.9173 - val_acc: 0.6914 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.8317 - acc: 0.7104 - val_loss: 0.8750 - val_acc: 0.7104 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.7885 - acc: 0.7269 - val_loss: 0.8980 - val_acc: 0.7067 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 0.7865 - acc: 0.7358 - val_loss: 0.9126 - val_acc: 0.6840 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 0.7658 - acc: 0.7395 - val_loss: 0.8984 - val_acc: 0.6908 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.7496 - acc: 0.7482 - val_loss: 1.0162 - val_acc: 0.6750 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.7497 - acc: 0.7479 - val_loss: 0.9002 - val_acc: 0.7073 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.7248 - acc: 0.7541 - val_loss: 0.8025 - val_acc: 0.7353 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 0.6900 - acc: 0.7713 - val_loss: 0.8382 - val_acc: 0.7189 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6944 - acc: 0.7717 - val_loss: 0.8189 - val_acc: 0.7401 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.7152 - acc: 0.7638 - val_loss: 0.9225 - val_acc: 0.7020 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6963 - acc: 0.7668 - val_loss: 0.7978 - val_acc: 0.7332 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.6677 - acc: 0.7798 - val_loss: 0.8421 - val_acc: 0.7215 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.7164 - acc: 0.7671 - val_loss: 0.8766 - val_acc: 0.6993 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6759 - acc: 0.7881 - val_loss: 0.7919 - val_acc: 0.7353 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.6505 - acc: 0.7954 - val_loss: 0.8176 - val_acc: 0.7385 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.6490 - acc: 0.7981 - val_loss: 0.8434 - val_acc: 0.7263 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6479 - acc: 0.7881 - val_loss: 0.8319 - val_acc: 0.7411 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 16s 539ms/step - loss: 0.6566 - acc: 0.7862 - val_loss: 0.8172 - val_acc: 0.7290 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.6271 - acc: 0.7984 - val_loss: 0.8163 - val_acc: 0.7369 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.5930 - acc: 0.8146 - val_loss: 0.7550 - val_acc: 0.7639 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6260 - acc: 0.8047 - val_loss: 0.9888 - val_acc: 0.6993 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.6138 - acc: 0.8035 - val_loss: 0.8998 - val_acc: 0.7305 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6236 - acc: 0.8032 - val_loss: 0.7760 - val_acc: 0.7491 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.6098 - acc: 0.8097 - val_loss: 0.8004 - val_acc: 0.7565 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 0.6206 - acc: 0.8032 - val_loss: 0.8545 - val_acc: 0.7390 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 16s 538ms/step - loss: 0.5935 - acc: 0.8157 - val_loss: 0.8309 - val_acc: 0.7422 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 16s 537ms/step - loss: 0.5811 - acc: 0.8211 - val_loss: 0.8601 - val_acc: 0.7088 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.5684 - acc: 0.8273 - val_loss: 0.7836 - val_acc: 0.7623 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.6041 - acc: 0.8124 - val_loss: 1.0792 - val_acc: 0.7009 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 16s 536ms/step - loss: 0.5830 - acc: 0.8262 - val_loss: 0.8029 - val_acc: 0.7401 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.5777 - acc: 0.8260 - val_loss: 0.8335 - val_acc: 0.7470 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.5588 - acc: 0.8359 - val_loss: 0.8213 - val_acc: 0.7470 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.5264 - acc: 0.8443 - val_loss: 0.8616 - val_acc: 0.7448 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.5562 - acc: 0.8321 - val_loss: 0.7962 - val_acc: 0.7438 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.5660 - acc: 0.8370 - val_loss: 0.9336 - val_acc: 0.7258 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.5780 - acc: 0.8270 - val_loss: 0.7820 - val_acc: 0.7496 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.5364 - acc: 0.8507 - val_loss: 0.8055 - val_acc: 0.7581 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.5106 - acc: 0.8537 - val_loss: 0.8155 - val_acc: 0.7485 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.5734 - acc: 0.8316 - val_loss: 0.8458 - val_acc: 0.7448 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.5924 - acc: 0.8283 - val_loss: 0.7671 - val_acc: 0.7745 - lr: 0.0200\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.4212 - acc: 0.8955 - val_loss: 0.6963 - val_acc: 0.7867 - lr: 0.0200\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.3548 - acc: 0.9188 - val_loss: 0.6960 - val_acc: 0.7962 - lr: 0.0200\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.3281 - acc: 0.9269 - val_loss: 0.6655 - val_acc: 0.8015 - lr: 0.0200\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.3171 - acc: 0.9274 - val_loss: 0.6961 - val_acc: 0.7867 - lr: 0.0200\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2838 - acc: 0.9412 - val_loss: 0.6857 - val_acc: 0.7978 - lr: 0.0200\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2633 - acc: 0.9457 - val_loss: 0.6939 - val_acc: 0.8004 - lr: 0.0200\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2643 - acc: 0.9382 - val_loss: 0.6941 - val_acc: 0.7957 - lr: 0.0200\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2524 - acc: 0.9425 - val_loss: 0.7049 - val_acc: 0.7941 - lr: 0.0200\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.2431 - acc: 0.9460 - val_loss: 0.7363 - val_acc: 0.7935 - lr: 0.0200\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.2385 - acc: 0.9479 - val_loss: 0.7247 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.2257 - acc: 0.9538 - val_loss: 0.7325 - val_acc: 0.7967 - lr: 0.0200\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2112 - acc: 0.9568 - val_loss: 0.7445 - val_acc: 0.7946 - lr: 0.0200\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2169 - acc: 0.9536 - val_loss: 0.7682 - val_acc: 0.7888 - lr: 0.0200\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2202 - acc: 0.9484 - val_loss: 0.7587 - val_acc: 0.7935 - lr: 0.0200\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2019 - acc: 0.9584 - val_loss: 0.7197 - val_acc: 0.8062 - lr: 0.0200\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2122 - acc: 0.9493 - val_loss: 0.7677 - val_acc: 0.7904 - lr: 0.0200\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2163 - acc: 0.9474 - val_loss: 0.7909 - val_acc: 0.7877 - lr: 0.0200\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2314 - acc: 0.9417 - val_loss: 0.8031 - val_acc: 0.7819 - lr: 0.0200\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2161 - acc: 0.9466 - val_loss: 0.7516 - val_acc: 0.7983 - lr: 0.0200\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2105 - acc: 0.9468 - val_loss: 0.7716 - val_acc: 0.8025 - lr: 0.0200\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2010 - acc: 0.9549 - val_loss: 0.7729 - val_acc: 0.7898 - lr: 0.0200\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2142 - acc: 0.9484 - val_loss: 0.8297 - val_acc: 0.7872 - lr: 0.0200\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2222 - acc: 0.9466 - val_loss: 0.8205 - val_acc: 0.7835 - lr: 0.0200\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1935 - acc: 0.9571 - val_loss: 0.7979 - val_acc: 0.7967 - lr: 0.0200\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2179 - acc: 0.9449 - val_loss: 0.8520 - val_acc: 0.7792 - lr: 0.0200\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2229 - acc: 0.9430 - val_loss: 0.8504 - val_acc: 0.7750 - lr: 0.0200\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2414 - acc: 0.9336 - val_loss: 0.8715 - val_acc: 0.7766 - lr: 0.0200\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2006 - acc: 0.9555 - val_loss: 0.8180 - val_acc: 0.7882 - lr: 0.0200\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1880 - acc: 0.9565 - val_loss: 0.8308 - val_acc: 0.7782 - lr: 0.0200\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1934 - acc: 0.9582 - val_loss: 0.8199 - val_acc: 0.8004 - lr: 0.0200\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 15s 530ms/step - loss: 0.2137 - acc: 0.9444 - val_loss: 0.8435 - val_acc: 0.7845 - lr: 0.0200\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1972 - acc: 0.9538 - val_loss: 0.7817 - val_acc: 0.8020 - lr: 0.0200\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2054 - acc: 0.9503 - val_loss: 0.8941 - val_acc: 0.7681 - lr: 0.0200\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.2027 - acc: 0.9490 - val_loss: 0.8117 - val_acc: 0.7935 - lr: 0.0200\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2097 - acc: 0.9538 - val_loss: 0.8407 - val_acc: 0.7893 - lr: 0.0200\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1909 - acc: 0.9565 - val_loss: 0.8946 - val_acc: 0.7798 - lr: 0.0200\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.2007 - acc: 0.9528 - val_loss: 0.8561 - val_acc: 0.7830 - lr: 0.0200\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2145 - acc: 0.9439 - val_loss: 0.8287 - val_acc: 0.7978 - lr: 0.0200\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2110 - acc: 0.9455 - val_loss: 0.8351 - val_acc: 0.7914 - lr: 0.0200\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1985 - acc: 0.9541 - val_loss: 0.8268 - val_acc: 0.8004 - lr: 0.0200\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1923 - acc: 0.9541 - val_loss: 0.8533 - val_acc: 0.7930 - lr: 0.0200\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1745 - acc: 0.9630 - val_loss: 0.8350 - val_acc: 0.8004 - lr: 0.0200\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1756 - acc: 0.9646 - val_loss: 0.8632 - val_acc: 0.7935 - lr: 0.0200\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1778 - acc: 0.9587 - val_loss: 0.8133 - val_acc: 0.7999 - lr: 0.0200\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2059 - acc: 0.9501 - val_loss: 0.9230 - val_acc: 0.7951 - lr: 0.0200\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2170 - acc: 0.9482 - val_loss: 0.8773 - val_acc: 0.7877 - lr: 0.0200\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.2171 - acc: 0.9420 - val_loss: 0.8657 - val_acc: 0.7840 - lr: 0.0200\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1926 - acc: 0.9530 - val_loss: 0.8587 - val_acc: 0.7808 - lr: 0.0200\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1799 - acc: 0.9641 - val_loss: 0.8153 - val_acc: 0.7935 - lr: 0.0200\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1693 - acc: 0.9628 - val_loss: 0.9018 - val_acc: 0.7909 - lr: 0.0200\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1862 - acc: 0.9574 - val_loss: 0.8414 - val_acc: 0.7898 - lr: 0.0200\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1782 - acc: 0.9633 - val_loss: 0.8807 - val_acc: 0.7845 - lr: 0.0200\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1841 - acc: 0.9590 - val_loss: 0.8379 - val_acc: 0.7909 - lr: 0.0200\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1888 - acc: 0.9560 - val_loss: 0.8251 - val_acc: 0.7925 - lr: 0.0200\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1946 - acc: 0.9571 - val_loss: 0.8275 - val_acc: 0.7904 - lr: 0.0200\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1879 - acc: 0.9574 - val_loss: 0.8809 - val_acc: 0.7882 - lr: 0.0200\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.1864 - acc: 0.9568 - val_loss: 0.8907 - val_acc: 0.7777 - lr: 0.0200\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1864 - acc: 0.9536 - val_loss: 0.8379 - val_acc: 0.7920 - lr: 0.0200\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1772 - acc: 0.9633 - val_loss: 0.8529 - val_acc: 0.7803 - lr: 0.0200\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.2175 - acc: 0.9444 - val_loss: 0.8009 - val_acc: 0.8121 - lr: 0.0040\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.1202 - acc: 0.9843 - val_loss: 0.7727 - val_acc: 0.8110 - lr: 0.0040\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.1073 - acc: 0.9889 - val_loss: 0.7735 - val_acc: 0.8168 - lr: 0.0040\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0966 - acc: 0.9930 - val_loss: 0.7873 - val_acc: 0.8121 - lr: 0.0040\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0853 - acc: 0.9957 - val_loss: 0.7949 - val_acc: 0.8126 - lr: 0.0040\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0813 - acc: 0.9973 - val_loss: 0.7882 - val_acc: 0.8152 - lr: 0.0040\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0810 - acc: 0.9957 - val_loss: 0.7747 - val_acc: 0.8142 - lr: 0.0040\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0777 - acc: 0.9976 - val_loss: 0.7673 - val_acc: 0.8131 - lr: 0.0040\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0763 - acc: 0.9962 - val_loss: 0.7930 - val_acc: 0.8174 - lr: 0.0040\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0741 - acc: 0.9962 - val_loss: 0.7739 - val_acc: 0.8163 - lr: 0.0040\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0714 - acc: 0.9976 - val_loss: 0.7730 - val_acc: 0.8195 - lr: 0.0040\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0724 - acc: 0.9968 - val_loss: 0.7992 - val_acc: 0.8158 - lr: 0.0040\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0681 - acc: 0.9984 - val_loss: 0.7975 - val_acc: 0.8147 - lr: 0.0040\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0676 - acc: 0.9973 - val_loss: 0.7773 - val_acc: 0.8168 - lr: 0.0040\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0648 - acc: 0.9984 - val_loss: 0.7938 - val_acc: 0.8142 - lr: 0.0040\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0637 - acc: 0.9981 - val_loss: 0.8084 - val_acc: 0.8163 - lr: 0.0040\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0642 - acc: 0.9976 - val_loss: 0.7868 - val_acc: 0.8211 - lr: 0.0040\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0634 - acc: 0.9978 - val_loss: 0.7776 - val_acc: 0.8184 - lr: 0.0040\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0621 - acc: 0.9989 - val_loss: 0.7812 - val_acc: 0.8227 - lr: 0.0040\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0598 - acc: 0.9984 - val_loss: 0.7740 - val_acc: 0.8184 - lr: 0.0040\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0586 - acc: 0.9981 - val_loss: 0.7993 - val_acc: 0.8147 - lr: 0.0040\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0598 - acc: 0.9984 - val_loss: 0.8073 - val_acc: 0.8147 - lr: 0.0040\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0573 - acc: 0.9989 - val_loss: 0.7981 - val_acc: 0.8163 - lr: 0.0040\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0598 - acc: 0.9970 - val_loss: 0.8044 - val_acc: 0.8190 - lr: 0.0040\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0578 - acc: 0.9978 - val_loss: 0.7994 - val_acc: 0.8211 - lr: 0.0040\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0550 - acc: 0.9992 - val_loss: 0.8159 - val_acc: 0.8158 - lr: 0.0040\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0563 - acc: 0.9981 - val_loss: 0.7760 - val_acc: 0.8200 - lr: 0.0040\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0525 - acc: 0.9995 - val_loss: 0.8213 - val_acc: 0.8205 - lr: 0.0040\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0526 - acc: 0.9992 - val_loss: 0.8315 - val_acc: 0.8137 - lr: 0.0040\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0516 - acc: 0.9987 - val_loss: 0.8266 - val_acc: 0.8142 - lr: 0.0040\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0534 - acc: 0.9973 - val_loss: 0.8214 - val_acc: 0.8137 - lr: 0.0040\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0518 - acc: 0.9984 - val_loss: 0.8472 - val_acc: 0.8126 - lr: 0.0040\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0516 - acc: 0.9984 - val_loss: 0.8556 - val_acc: 0.8131 - lr: 0.0040\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0488 - acc: 0.9997 - val_loss: 0.8380 - val_acc: 0.8174 - lr: 0.0040\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0486 - acc: 0.9992 - val_loss: 0.8092 - val_acc: 0.8200 - lr: 0.0040\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0486 - acc: 0.9989 - val_loss: 0.8528 - val_acc: 0.8100 - lr: 0.0040\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0469 - acc: 0.9992 - val_loss: 0.8524 - val_acc: 0.8190 - lr: 0.0040\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 15s 530ms/step - loss: 0.0484 - acc: 0.9981 - val_loss: 0.8184 - val_acc: 0.8147 - lr: 0.0040\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 15s 530ms/step - loss: 0.0475 - acc: 0.9992 - val_loss: 0.8522 - val_acc: 0.8158 - lr: 0.0040\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0488 - acc: 0.9973 - val_loss: 0.8730 - val_acc: 0.8105 - lr: 0.0040\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0478 - acc: 0.9989 - val_loss: 0.8412 - val_acc: 0.8147 - lr: 8.0000e-04\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0461 - acc: 0.9989 - val_loss: 0.8418 - val_acc: 0.8174 - lr: 8.0000e-04\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0449 - acc: 0.9997 - val_loss: 0.8329 - val_acc: 0.8147 - lr: 8.0000e-04\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0438 - acc: 0.9992 - val_loss: 0.8481 - val_acc: 0.8179 - lr: 8.0000e-04\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0447 - acc: 0.9992 - val_loss: 0.8270 - val_acc: 0.8205 - lr: 8.0000e-04\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0427 - acc: 0.9995 - val_loss: 0.8160 - val_acc: 0.8190 - lr: 8.0000e-04\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0433 - acc: 0.9995 - val_loss: 0.8693 - val_acc: 0.8147 - lr: 8.0000e-04\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0423 - acc: 0.9997 - val_loss: 0.8486 - val_acc: 0.8179 - lr: 8.0000e-04\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0422 - acc: 0.9997 - val_loss: 0.8435 - val_acc: 0.8205 - lr: 8.0000e-04\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0432 - acc: 0.9992 - val_loss: 0.8189 - val_acc: 0.8221 - lr: 8.0000e-04\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0412 - acc: 0.9995 - val_loss: 0.8201 - val_acc: 0.8205 - lr: 8.0000e-04\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0406 - acc: 0.9995 - val_loss: 0.8463 - val_acc: 0.8184 - lr: 8.0000e-04\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0416 - acc: 0.9995 - val_loss: 0.8535 - val_acc: 0.8158 - lr: 8.0000e-04\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0408 - acc: 0.9997 - val_loss: 0.8475 - val_acc: 0.8195 - lr: 8.0000e-04\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0410 - acc: 0.9997 - val_loss: 0.8401 - val_acc: 0.8184 - lr: 8.0000e-04\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0402 - acc: 0.9997 - val_loss: 0.8325 - val_acc: 0.8205 - lr: 8.0000e-04\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.8424 - val_acc: 0.8211 - lr: 8.0000e-04\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0399 - acc: 0.9997 - val_loss: 0.8502 - val_acc: 0.8221 - lr: 8.0000e-04\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0394 - acc: 0.9995 - val_loss: 0.8735 - val_acc: 0.8152 - lr: 8.0000e-04\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0398 - acc: 0.9997 - val_loss: 0.8508 - val_acc: 0.8221 - lr: 8.0000e-04\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0400 - acc: 0.9995 - val_loss: 0.8365 - val_acc: 0.8221 - lr: 8.0000e-04\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.8389 - val_acc: 0.8179 - lr: 8.0000e-04\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.0389 - acc: 0.9995 - val_loss: 0.8243 - val_acc: 0.8216 - lr: 8.0000e-04\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0389 - acc: 0.9995 - val_loss: 0.8383 - val_acc: 0.8179 - lr: 8.0000e-04\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0396 - acc: 0.9989 - val_loss: 0.8134 - val_acc: 0.8184 - lr: 8.0000e-04\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 16s 535ms/step - loss: 0.0381 - acc: 0.9989 - val_loss: 0.8343 - val_acc: 0.8269 - lr: 8.0000e-04\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0383 - acc: 0.9995 - val_loss: 0.8361 - val_acc: 0.8078 - lr: 8.0000e-04\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0381 - acc: 0.9992 - val_loss: 0.8248 - val_acc: 0.8211 - lr: 8.0000e-04\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0375 - acc: 0.9997 - val_loss: 0.8257 - val_acc: 0.8253 - lr: 8.0000e-04\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0368 - acc: 0.9995 - val_loss: 0.8372 - val_acc: 0.8232 - lr: 8.0000e-04\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0377 - acc: 0.9995 - val_loss: 0.8395 - val_acc: 0.8237 - lr: 8.0000e-04\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0367 - acc: 0.9997 - val_loss: 0.8452 - val_acc: 0.8280 - lr: 8.0000e-04\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0364 - acc: 0.9992 - val_loss: 0.8363 - val_acc: 0.8205 - lr: 8.0000e-04\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0366 - acc: 0.9997 - val_loss: 0.8313 - val_acc: 0.8190 - lr: 8.0000e-04\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.8395 - val_acc: 0.8195 - lr: 8.0000e-04\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0357 - acc: 1.0000 - val_loss: 0.8535 - val_acc: 0.8274 - lr: 8.0000e-04\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 15s 534ms/step - loss: 0.0359 - acc: 0.9997 - val_loss: 0.8485 - val_acc: 0.8216 - lr: 8.0000e-04\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 15s 533ms/step - loss: 0.0355 - acc: 0.9997 - val_loss: 0.8464 - val_acc: 0.8200 - lr: 8.0000e-04\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 15s 532ms/step - loss: 0.0352 - acc: 0.9997 - val_loss: 0.8337 - val_acc: 0.8184 - lr: 8.0000e-04\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 15s 531ms/step - loss: 0.0350 - acc: 1.0000 - val_loss: 0.8468 - val_acc: 0.8221 - lr: 8.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNGXxJTQq-UD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "64e2011d-01fc-4916-933d-7695c8319160"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-085dbac4dca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparseval_16_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m _, loss_value, summary = sess.run([train_op,parseval_16_2.losses],\n\u001b[1;32m      7\u001b[0m                                     feed_dict={X,to_categorical(y_train_df['New'])})\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "outputId": "1c403473-cd6c-4446-f013-e851f2ca5b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe5a109d5c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeg6MBf-GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_err = [1.0-x for x in hist.history['val_acc']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgiKT6i5GiJ9",
        "colab_type": "code",
        "outputId": "090feebf-b0e1-4a8a-cf74-45d50afc802b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "pyplot.plot(test_err, label='test')\n",
        "pyplot.savefig(\"deneme_err.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "parseval_16_2.save(\"parseval_tensor_lst.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqddlwbmEV9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = parseval_16_2.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ysop6NFDbs",
        "colab_type": "code",
        "outputId": "0343737d-7d1d-468d-8531-fe503a38d5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "parseval_16_2.evaluate(X_test,to_categorical(y_test_df['New']),batch_size=128,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 - 1s - loss: 0.8171 - acc: 0.8317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.817147433757782, 0.8316569328308105]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THYCAlBW15Kg",
        "colab_type": "code",
        "outputId": "c947688e-b185-4a4f-f4a4-d0c4f889e127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     || 87.9MB 35kB/s \n",
            "\u001b[K     || 3.1MB 52.2MB/s \n",
            "\u001b[K     || 501kB 56.3MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-nh_dsdoh/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-nh_dsdoh/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     || 163kB 31.1MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     || 51kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.4)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=708b7304ac7a6e28e4ef9ea44126f4a715f8f96b8ee650c8814df301078e521a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jif2zqq_/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-23-67a2c783edbc>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNev4Y9U2sFQ",
        "colab_type": "code",
        "outputId": "c87f32ea-ddb6-4e79-e7e5-4f90c61f1501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(wrn_28_10.input,wrn_28_10.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4733b5d5dfed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#The attack requires the model to ouput the logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogits_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrn_28_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrn_28_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wrn_28_10' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKEw7Uq3Dj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_index = 5\n",
        "\n",
        "original_image = X_test[random_index]\n",
        "original_image = tf.convert_to_tensor(original_image.reshape((1,68,100))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdxYTfSn3R4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSa4WKy33U3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_28_10(original_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jrP3jw83fwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_cat = to_categorical(y_test_df['New'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VoJsNJX4HiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_label = y_test_cat[random_index]\n",
        "original_label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70kNexu3l-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.33\n",
        "\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "adv_example_untargeted_label_pred = wrn_28_10.predict(adv_example_untargeted_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-LglBmM4gNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adv_example_untargeted_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d6rZhTp4i2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(adv_example_untargeted_label_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKCXvIXY66lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image = tf.reshape(adv_example_untargeted_label, (68,100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0jgK_uG7cwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70uI8BLT7r5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "X = np.random.random((100, 100)) # sample 2D array\n",
        "plt.imshow(original_image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SumJnhN98Y0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_cat[random_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woaZe08I8kM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[random_index]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}