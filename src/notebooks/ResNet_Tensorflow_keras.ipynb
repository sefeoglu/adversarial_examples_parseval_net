{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "outputId": "7379c162-7091-40be-c0a4-52a77476513c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "    wrn_16_2.summary()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   144         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   4608        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   512         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9216        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 32)   0           add[0][0]                        \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 64)   18432       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36864       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   2048        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   36864       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 16, 64)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 64)   0           add_2[0][0]                      \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 128)    73728       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 128)    512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 128)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 128)    147456      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    8192        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 128)    0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 128)    512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 128)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 128)    147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 8, 128)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 128)    512         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 128)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 128)    147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 128)    0           add_4[0][0]                      \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 128)    0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            516         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 692,436\n",
            "Trainable params: 690,612\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRh7YDqiuqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('data_set.pickle', 'rb') as f:\n",
        "    x = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONi_4KtjjNE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train,X_test, y_test, X_val, y_val = x['X_train'], x['y_train'], x['X_test'], x['y_test'], x['X_val'], x['y_val']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "outputId": "b8a89af9-b15e-428f-81f2-ba981804c810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "outputId": "2266e79c-ba96-48fd-9247-86b41b5c9362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "outputId": "fde82827-16be-4fb3-93a9-d908e5350f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "closed           1500\n",
              "open             1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "outputId": "0289812a-6ff3-4727-9b99-fe5276b85a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 128\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "outputId": "7b7d2aa0-373a-4d85-acad-c7f06df94f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.1\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "outputId": "ec4157af-e77c-4811-b1be-961ebef69afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = wrn_16_2.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 109ms/step - loss: 1.5927 - acc: 0.3191 - val_loss: 1.5627 - val_acc: 0.3437 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.5171 - acc: 0.3648 - val_loss: 1.5000 - val_acc: 0.3709 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.4876 - acc: 0.3622 - val_loss: 1.4778 - val_acc: 0.3650 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.4713 - acc: 0.3706 - val_loss: 1.4615 - val_acc: 0.3806 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.4524 - acc: 0.3890 - val_loss: 1.4756 - val_acc: 0.3650 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.4454 - acc: 0.4001 - val_loss: 1.4498 - val_acc: 0.3806 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.4350 - acc: 0.4161 - val_loss: 1.4871 - val_acc: 0.3942 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.4188 - acc: 0.4336 - val_loss: 1.3963 - val_acc: 0.4602 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4068 - acc: 0.4561 - val_loss: 1.3567 - val_acc: 0.4913 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.3913 - acc: 0.4660 - val_loss: 1.5235 - val_acc: 0.3981 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.3795 - acc: 0.4738 - val_loss: 1.4119 - val_acc: 0.4583 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.3458 - acc: 0.5051 - val_loss: 1.3927 - val_acc: 0.4621 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.3074 - acc: 0.5317 - val_loss: 2.3812 - val_acc: 0.3087 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.2788 - acc: 0.5522 - val_loss: 2.1484 - val_acc: 0.3476 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.2482 - acc: 0.5661 - val_loss: 1.2152 - val_acc: 0.5728 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2162 - acc: 0.5772 - val_loss: 1.1456 - val_acc: 0.5961 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.1724 - acc: 0.5959 - val_loss: 1.3802 - val_acc: 0.4893 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1564 - acc: 0.6025 - val_loss: 1.6463 - val_acc: 0.4000 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.1070 - acc: 0.6407 - val_loss: 1.2157 - val_acc: 0.5942 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.0989 - acc: 0.6380 - val_loss: 1.1364 - val_acc: 0.6369 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0517 - acc: 0.6616 - val_loss: 1.1129 - val_acc: 0.6155 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.0365 - acc: 0.6715 - val_loss: 1.1210 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0318 - acc: 0.6749 - val_loss: 1.2265 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 1.0375 - acc: 0.6620 - val_loss: 1.2368 - val_acc: 0.6136 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9978 - acc: 0.6864 - val_loss: 1.0749 - val_acc: 0.6427 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9961 - acc: 0.6844 - val_loss: 1.4965 - val_acc: 0.5107 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9998 - acc: 0.6862 - val_loss: 1.2246 - val_acc: 0.6019 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9576 - acc: 0.6980 - val_loss: 1.1244 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9467 - acc: 0.7064 - val_loss: 1.6764 - val_acc: 0.4913 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9506 - acc: 0.7048 - val_loss: 0.9955 - val_acc: 0.7068 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9321 - acc: 0.7133 - val_loss: 0.9720 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9159 - acc: 0.7233 - val_loss: 0.9419 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8964 - acc: 0.7339 - val_loss: 0.9462 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8828 - acc: 0.7381 - val_loss: 0.9684 - val_acc: 0.6990 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8753 - acc: 0.7432 - val_loss: 0.9513 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8619 - acc: 0.7472 - val_loss: 0.9719 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8656 - acc: 0.7432 - val_loss: 0.9602 - val_acc: 0.6932 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8513 - acc: 0.7550 - val_loss: 0.9414 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8584 - acc: 0.7461 - val_loss: 0.9429 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8531 - acc: 0.7492 - val_loss: 0.9584 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8478 - acc: 0.7568 - val_loss: 0.9454 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8440 - acc: 0.7512 - val_loss: 0.9428 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8434 - acc: 0.7537 - val_loss: 0.9382 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8424 - acc: 0.7508 - val_loss: 0.9632 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8401 - acc: 0.7470 - val_loss: 0.9279 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8467 - acc: 0.7490 - val_loss: 0.9445 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8351 - acc: 0.7621 - val_loss: 0.9493 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8364 - acc: 0.7559 - val_loss: 0.9592 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8439 - acc: 0.7501 - val_loss: 0.9368 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8283 - acc: 0.7612 - val_loss: 0.9537 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8353 - acc: 0.7608 - val_loss: 0.9729 - val_acc: 0.6874 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8330 - acc: 0.7537 - val_loss: 0.9500 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8377 - acc: 0.7545 - val_loss: 0.9394 - val_acc: 0.6932 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8167 - acc: 0.7623 - val_loss: 0.9609 - val_acc: 0.6874 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8329 - acc: 0.7550 - val_loss: 0.9882 - val_acc: 0.6951 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8282 - acc: 0.7517 - val_loss: 0.9877 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8285 - acc: 0.7589 - val_loss: 0.9492 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8310 - acc: 0.7572 - val_loss: 0.9325 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8353 - acc: 0.7534 - val_loss: 0.9878 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8275 - acc: 0.7577 - val_loss: 0.9487 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8232 - acc: 0.7565 - val_loss: 0.9880 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8211 - acc: 0.7643 - val_loss: 0.9452 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8298 - acc: 0.7623 - val_loss: 0.9406 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8253 - acc: 0.7572 - val_loss: 0.9573 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8227 - acc: 0.7579 - val_loss: 0.9312 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8323 - acc: 0.7565 - val_loss: 0.9795 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8313 - acc: 0.7557 - val_loss: 0.9428 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8306 - acc: 0.7541 - val_loss: 0.9708 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8312 - acc: 0.7534 - val_loss: 0.9598 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8238 - acc: 0.7588 - val_loss: 0.9399 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8264 - acc: 0.7561 - val_loss: 0.9413 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8229 - acc: 0.7590 - val_loss: 0.9442 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8174 - acc: 0.7648 - val_loss: 0.9544 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8250 - acc: 0.7552 - val_loss: 0.9369 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8270 - acc: 0.7599 - val_loss: 0.9356 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8279 - acc: 0.7585 - val_loss: 0.9584 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8172 - acc: 0.7690 - val_loss: 0.9535 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8333 - acc: 0.7572 - val_loss: 0.9761 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8210 - acc: 0.7659 - val_loss: 0.9818 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8282 - acc: 0.7599 - val_loss: 0.9590 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8188 - acc: 0.7603 - val_loss: 0.9492 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8271 - acc: 0.7583 - val_loss: 0.9498 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8260 - acc: 0.7570 - val_loss: 0.9885 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8221 - acc: 0.7621 - val_loss: 0.9517 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8191 - acc: 0.7636 - val_loss: 0.9718 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8311 - acc: 0.7614 - val_loss: 0.9609 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8349 - acc: 0.7648 - val_loss: 0.9378 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8244 - acc: 0.7552 - val_loss: 0.9532 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8298 - acc: 0.7605 - val_loss: 0.9703 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8174 - acc: 0.7623 - val_loss: 0.9618 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8264 - acc: 0.7563 - val_loss: 0.9651 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8342 - acc: 0.7623 - val_loss: 0.9847 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8267 - acc: 0.7601 - val_loss: 0.9453 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8188 - acc: 0.7617 - val_loss: 0.9652 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8203 - acc: 0.7672 - val_loss: 1.0173 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8222 - acc: 0.7565 - val_loss: 1.0118 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8200 - acc: 0.7585 - val_loss: 0.9676 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8244 - acc: 0.7610 - val_loss: 0.9967 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8152 - acc: 0.7668 - val_loss: 0.9452 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8192 - acc: 0.7599 - val_loss: 0.9808 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8240 - acc: 0.7610 - val_loss: 0.9646 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8247 - acc: 0.7548 - val_loss: 0.9637 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8258 - acc: 0.7543 - val_loss: 0.9609 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8247 - acc: 0.7568 - val_loss: 0.9600 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8149 - acc: 0.7645 - val_loss: 0.9710 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8231 - acc: 0.7592 - val_loss: 0.9756 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8226 - acc: 0.7585 - val_loss: 0.9496 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8339 - acc: 0.7570 - val_loss: 0.9563 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8232 - acc: 0.7656 - val_loss: 0.9697 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8289 - acc: 0.7603 - val_loss: 0.9358 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8266 - acc: 0.7534 - val_loss: 1.0093 - val_acc: 0.6854 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8192 - acc: 0.7668 - val_loss: 0.9714 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8284 - acc: 0.7572 - val_loss: 1.0502 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8320 - acc: 0.7568 - val_loss: 0.9832 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8298 - acc: 0.7494 - val_loss: 0.9783 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8272 - acc: 0.7601 - val_loss: 0.9566 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8252 - acc: 0.7548 - val_loss: 1.0368 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8215 - acc: 0.7634 - val_loss: 0.9443 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8291 - acc: 0.7572 - val_loss: 0.9792 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8248 - acc: 0.7541 - val_loss: 0.9965 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8263 - acc: 0.7577 - val_loss: 0.9538 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8261 - acc: 0.7608 - val_loss: 0.9569 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8249 - acc: 0.7670 - val_loss: 0.9840 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8231 - acc: 0.7597 - val_loss: 0.9656 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8215 - acc: 0.7619 - val_loss: 0.9706 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8234 - acc: 0.7617 - val_loss: 0.9460 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8300 - acc: 0.7634 - val_loss: 0.9521 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8319 - acc: 0.7565 - val_loss: 0.9572 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8186 - acc: 0.7676 - val_loss: 0.9555 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8187 - acc: 0.7672 - val_loss: 0.9569 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8308 - acc: 0.7568 - val_loss: 0.9660 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8282 - acc: 0.7543 - val_loss: 0.9592 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8258 - acc: 0.7583 - val_loss: 0.9454 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8243 - acc: 0.7619 - val_loss: 0.9447 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8206 - acc: 0.7623 - val_loss: 0.9727 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8278 - acc: 0.7574 - val_loss: 0.9503 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8184 - acc: 0.7634 - val_loss: 1.0514 - val_acc: 0.6796 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8192 - acc: 0.7554 - val_loss: 0.9564 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8229 - acc: 0.7559 - val_loss: 0.9655 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8244 - acc: 0.7650 - val_loss: 0.9692 - val_acc: 0.6854 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8197 - acc: 0.7650 - val_loss: 0.9585 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8143 - acc: 0.7628 - val_loss: 0.9701 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8280 - acc: 0.7543 - val_loss: 0.9712 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8230 - acc: 0.7585 - val_loss: 0.9532 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8314 - acc: 0.7483 - val_loss: 0.9603 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8233 - acc: 0.7574 - val_loss: 0.9719 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8241 - acc: 0.7585 - val_loss: 0.9447 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8272 - acc: 0.7559 - val_loss: 0.9403 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8280 - acc: 0.7641 - val_loss: 0.9464 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8285 - acc: 0.7572 - val_loss: 0.9626 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8257 - acc: 0.7628 - val_loss: 0.9540 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8275 - acc: 0.7548 - val_loss: 0.9762 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8144 - acc: 0.7683 - val_loss: 0.9479 - val_acc: 0.6932 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8269 - acc: 0.7501 - val_loss: 0.9422 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8279 - acc: 0.7570 - val_loss: 0.9404 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8141 - acc: 0.7628 - val_loss: 0.9521 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8192 - acc: 0.7554 - val_loss: 0.9809 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8220 - acc: 0.7641 - val_loss: 0.9445 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8245 - acc: 0.7539 - val_loss: 0.9556 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8275 - acc: 0.7623 - val_loss: 0.9411 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8220 - acc: 0.7636 - val_loss: 0.9470 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8215 - acc: 0.7634 - val_loss: 0.9732 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8141 - acc: 0.7608 - val_loss: 0.9548 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8178 - acc: 0.7617 - val_loss: 0.9345 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8227 - acc: 0.7636 - val_loss: 0.9363 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8318 - acc: 0.7601 - val_loss: 0.9863 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8313 - acc: 0.7603 - val_loss: 0.9653 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8327 - acc: 0.7581 - val_loss: 0.9466 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8268 - acc: 0.7583 - val_loss: 0.9668 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8226 - acc: 0.7652 - val_loss: 0.9312 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8259 - acc: 0.7590 - val_loss: 0.9835 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8213 - acc: 0.7617 - val_loss: 0.9774 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8173 - acc: 0.7692 - val_loss: 0.9524 - val_acc: 0.6913 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8266 - acc: 0.7532 - val_loss: 0.9399 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8227 - acc: 0.7601 - val_loss: 0.9818 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8262 - acc: 0.7583 - val_loss: 0.9558 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8204 - acc: 0.7668 - val_loss: 0.9679 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8204 - acc: 0.7645 - val_loss: 0.9385 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8297 - acc: 0.7512 - val_loss: 0.9465 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8156 - acc: 0.7699 - val_loss: 1.0019 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8254 - acc: 0.7639 - val_loss: 0.9706 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8198 - acc: 0.7604 - val_loss: 0.9568 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8299 - acc: 0.7594 - val_loss: 0.9407 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8154 - acc: 0.7594 - val_loss: 0.9527 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8229 - acc: 0.7645 - val_loss: 0.9539 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8244 - acc: 0.7572 - val_loss: 0.9806 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8289 - acc: 0.7583 - val_loss: 0.9713 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8227 - acc: 0.7605 - val_loss: 0.9935 - val_acc: 0.6854 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8194 - acc: 0.7643 - val_loss: 0.9680 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8191 - acc: 0.7628 - val_loss: 0.9721 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8199 - acc: 0.7623 - val_loss: 0.9847 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8201 - acc: 0.7610 - val_loss: 0.9891 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8195 - acc: 0.7639 - val_loss: 0.9480 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8192 - acc: 0.7603 - val_loss: 0.9759 - val_acc: 0.6951 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8248 - acc: 0.7561 - val_loss: 0.9565 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8255 - acc: 0.7654 - val_loss: 1.0042 - val_acc: 0.6893 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8247 - acc: 0.7608 - val_loss: 0.9408 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8288 - acc: 0.7592 - val_loss: 0.9602 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8195 - acc: 0.7634 - val_loss: 0.9730 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8223 - acc: 0.7581 - val_loss: 0.9867 - val_acc: 0.6971 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.save(\"wrn_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djH4uwAnvkfb",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "outputId": "e83b8409-bb6a-486d-a71f-ddb28cee94ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "outputId": "a2c1102b-35f5-49f4-9348-84f4cf0bd35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8932 - acc: 0.7347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8932190537452698, 0.7347294688224792]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QB8zFSSU7Qy",
        "colab_type": "code",
        "outputId": "abc048c2-9fdf-4f86-bfff-265efcb3a62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     || 87.9MB 1.3MB/s \n",
            "\u001b[K     || 3.1MB 44.1MB/s \n",
            "\u001b[K     || 501kB 28.3MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-fvamj8wu/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-fvamj8wu/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     || 163kB 2.7MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     || 51kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=2021835bda95069946ff2aa00c1fe63a9df29c1a7597fb221af9f86998e6d289\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tk4xkquq/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-14-67a2c783edbc>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bfZ4G8W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "wrn_16_2 = tf.keras.models.load_model(\"modelwrn.h5\")\n",
        "logits_model = tf.keras.Model(wrn_16_2.input,wrn_16_2.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWIlakqVD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv = []\n",
        "epsilon_list = [0.004]\n",
        "for j in range(len(epsilon_list)):\n",
        "  epsilon = epsilon_list[j]\n",
        "  for i in range(len(X_test)):\n",
        "    random_index = i\n",
        "    original_image = X_test[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_test[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8XZJIGBkUku",
        "colab_type": "code",
        "outputId": "5e4326da-519e-44c0-fe25-cf74e389c131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 0.9512 - acc: 0.7208\n",
            "epsilon: 0.004 and test evalution : [0.9512437582015991, 0.7207679152488708]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB2PbXrudUWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "719a61f6-8669-4c35-fca1-e4837c6ef070"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.729506492614746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DCXV9Tc9B0",
        "colab_type": "code",
        "outputId": "3fd01d51-210b-4a8a-ffa9-941e5e6ee023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 0.9936 - acc: 0.6963\n",
            "epsilon: 0.005 and test evalution : [0.9935703277587891, 0.6963350772857666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGgsDCDodU_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca915d0-7ae4-485f-840d-dba95536e0d0"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.79124450683594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Ah3eA2kYBp",
        "colab_type": "code",
        "outputId": "5d2ff907-67e1-4c73-bbff-127ef01b03b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 11ms/step - loss: 1.2240 - acc: 0.6126\n",
            "epsilon: 0.01 and test evalution : [1.2239612340927124, 0.6125654578208923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjfdNA70dVoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bc121fa-843f-4cb5-9d33-92f25677c472"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.77065086364746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xed10n0QmMqr",
        "colab_type": "code",
        "outputId": "ef3c590c-af94-434b-dbe9-946474ae921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 1.7284 - acc: 0.4712\n",
            "epsilon: 0.02 and test evalution : [1.7284008264541626, 0.4712041914463043]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbqrQrSZdWX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fdd6c29-6596-43e9-9245-c5f1e0329935"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.75005006790161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfF0d5ePbXK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv = np.array(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5I9X-0mboqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df = pd.DataFrame(y_adv, columns=['Encoded'])\n",
        "y_adv_df['Encoded'] = labelencoder.fit_transform(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcxHP-bTcIwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df['Encoded'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1mGBoQbd46-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = []\n",
        "X_adv =my_data['image']\n",
        "for i in range(len(X_adv)):\n",
        "  a = np.array(X_adv[i])\n",
        "  X_new.append(a.reshape(68,100,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdE_WN8Ffgyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X)):\n",
        "  a = np.array(X[i])\n",
        "  X_new.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAnXO0Vfg1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_third = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jH1i_FMA2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dackr68mMA0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UIXimpiKWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_new = []\n",
        "for j in range(0,2):\n",
        "  for i in range(len(y_cat)):\n",
        "    y_new.append(y_cat[i])\n",
        "y_third = np.array(y_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuRIuXcNiKY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_all, y_all = X_third, y_third"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXveP1Veo7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split( X_all,y_all, test_size = 0.33, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJjEg9qiI0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HibsOpTIcNq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q96wjHqxeTJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n",
        "BS_adv= 100\n",
        "EPOCHS_adv = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jewqs8yxlnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch_train(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.1\n",
        "    elif epoch <20:\n",
        "        return 0.1/2.0\n",
        "    elif epoch < 30:\n",
        "        return 0.1/2.0**2\n",
        "    elif epoch < 40:\n",
        "        return 0.1/2.0**3\n",
        "    else:\n",
        "        return 0.1/2.0**4\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler_train = LearningRateScheduler(lr_sch_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FIn8khEd45J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hist = wrn_16_2_adv.fit_generator(generator.flow(X_train_adv, y_train_adv, batch_size=BS_adv), steps_per_epoch=len(X_train_adv) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test_adv, y_test_adv),\n",
        "                   validation_steps=X_test_adv.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qXnteSOpFZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.save(\"model_adv_wrn_tensor_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeetxZrNv9oM",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S5IjLivpMbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcU_6z90QSJ",
        "colab_type": "text"
      },
      "source": [
        "**CleanExperiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5qUE6j0JUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4p2TUIj0csZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQljdkd0he9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_clean = wrn_16_2_clean.fit_generator(generator.flow(X_train, y_train, batch_size=BS_adv), steps_per_epoch=len(X_train) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acrchBU185p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.save(\"model_adv_train_clean_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9hLRXbmwETE",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pgU_KsH0yVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist_clean\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCKONCZ0Jzfi",
        "colab_type": "text"
      },
      "source": [
        "**Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgpFgWbKeR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiqvES18c-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHVWy96Llce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqj_Ax7MI4SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXT3YD6iLl0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test_adv,y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fKhEMXgKAnZ",
        "colab_type": "text"
      },
      "source": [
        "**Non_Adversarial_Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouj6OqTD8VdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfkUSeV6KHp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFJl2D4Hbxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gJh7MDHChHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZuONcAeAwQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test_adv, y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}