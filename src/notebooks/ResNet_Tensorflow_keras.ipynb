{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e7a5445d-2c74-47f0-e796-3228693d64c9"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "    #wrn_16_2.summary()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRh7YDqiuqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('data_set.pickle', 'rb') as f:\n",
        "    x = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONi_4KtjjNE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train,X_test, y_test, X_val, y_val = x['X_train'], x['y_train'], x['X_test'], x['y_test'], x['X_val'], x['y_val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7202541f-29c1-47f6-ab4a-24b63d7a3bf9"
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "535bf223-c635-4bd2-f1e1-fcb342c3b302"
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 128\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13c87254-6b7a-445e-ed63-7629afc27def"
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.1\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 60:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c31435a-00a1-4c29-cf84-a0a2eca86078"
      },
      "source": [
        "hist = wrn_16_2.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 4s 115ms/step - loss: 1.5891 - acc: 0.3118 - val_loss: 1.5415 - val_acc: 0.3437 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.5056 - acc: 0.3653 - val_loss: 1.5103 - val_acc: 0.3456 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4824 - acc: 0.3804 - val_loss: 1.4429 - val_acc: 0.3612 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4670 - acc: 0.3846 - val_loss: 1.4684 - val_acc: 0.4272 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.4615 - acc: 0.3953 - val_loss: 1.4844 - val_acc: 0.3456 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4440 - acc: 0.4057 - val_loss: 1.4121 - val_acc: 0.4350 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4417 - acc: 0.4159 - val_loss: 1.4372 - val_acc: 0.3845 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4149 - acc: 0.4303 - val_loss: 1.5062 - val_acc: 0.4233 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4105 - acc: 0.4494 - val_loss: 1.4437 - val_acc: 0.4136 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4050 - acc: 0.4587 - val_loss: 1.3324 - val_acc: 0.4913 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.3564 - acc: 0.5007 - val_loss: 1.4835 - val_acc: 0.3806 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.3418 - acc: 0.5102 - val_loss: 1.3029 - val_acc: 0.5340 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.3241 - acc: 0.5209 - val_loss: 1.3016 - val_acc: 0.5398 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.2925 - acc: 0.5364 - val_loss: 1.3461 - val_acc: 0.5379 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2615 - acc: 0.5524 - val_loss: 1.4862 - val_acc: 0.4524 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2286 - acc: 0.5863 - val_loss: 1.3323 - val_acc: 0.5223 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1920 - acc: 0.5970 - val_loss: 1.5727 - val_acc: 0.4990 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1784 - acc: 0.6032 - val_loss: 1.0895 - val_acc: 0.6233 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1331 - acc: 0.6276 - val_loss: 1.2125 - val_acc: 0.6078 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1119 - acc: 0.6334 - val_loss: 1.0898 - val_acc: 0.6583 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.0910 - acc: 0.6498 - val_loss: 1.2490 - val_acc: 0.6175 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0757 - acc: 0.6507 - val_loss: 1.0445 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0554 - acc: 0.6633 - val_loss: 1.1149 - val_acc: 0.6602 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0494 - acc: 0.6636 - val_loss: 1.1526 - val_acc: 0.6252 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.0342 - acc: 0.6667 - val_loss: 1.1162 - val_acc: 0.6485 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.0069 - acc: 0.6742 - val_loss: 1.1721 - val_acc: 0.6233 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9985 - acc: 0.6862 - val_loss: 1.2318 - val_acc: 0.6252 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9870 - acc: 0.6893 - val_loss: 0.9478 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9830 - acc: 0.6984 - val_loss: 1.0351 - val_acc: 0.6796 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9688 - acc: 0.7031 - val_loss: 1.0529 - val_acc: 0.7029 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9276 - acc: 0.7188 - val_loss: 0.9925 - val_acc: 0.7010 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9110 - acc: 0.7301 - val_loss: 0.9591 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9098 - acc: 0.7235 - val_loss: 0.9698 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9023 - acc: 0.7273 - val_loss: 0.9480 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8946 - acc: 0.7348 - val_loss: 0.9577 - val_acc: 0.7184 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8991 - acc: 0.7357 - val_loss: 0.9435 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8884 - acc: 0.7337 - val_loss: 0.9458 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8901 - acc: 0.7357 - val_loss: 0.9291 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8799 - acc: 0.7395 - val_loss: 0.9297 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8908 - acc: 0.7344 - val_loss: 0.9000 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8764 - acc: 0.7359 - val_loss: 0.9171 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8863 - acc: 0.7410 - val_loss: 0.9092 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8853 - acc: 0.7443 - val_loss: 0.9093 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8855 - acc: 0.7364 - val_loss: 0.9252 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8747 - acc: 0.7481 - val_loss: 0.9161 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8740 - acc: 0.7437 - val_loss: 0.9244 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8708 - acc: 0.7423 - val_loss: 0.9112 - val_acc: 0.7417 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8656 - acc: 0.7548 - val_loss: 0.9038 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8639 - acc: 0.7565 - val_loss: 0.9270 - val_acc: 0.7320 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8695 - acc: 0.7472 - val_loss: 0.9397 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8673 - acc: 0.7439 - val_loss: 0.9071 - val_acc: 0.7398 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8624 - acc: 0.7494 - val_loss: 0.9319 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8574 - acc: 0.7530 - val_loss: 0.9673 - val_acc: 0.7301 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8640 - acc: 0.7459 - val_loss: 0.9166 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8699 - acc: 0.7481 - val_loss: 0.9439 - val_acc: 0.7223 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8570 - acc: 0.7503 - val_loss: 0.9330 - val_acc: 0.7262 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8664 - acc: 0.7435 - val_loss: 0.9138 - val_acc: 0.7359 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8622 - acc: 0.7474 - val_loss: 0.9193 - val_acc: 0.7379 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8551 - acc: 0.7530 - val_loss: 0.9192 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8629 - acc: 0.7526 - val_loss: 0.9138 - val_acc: 0.7437 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8568 - acc: 0.7550 - val_loss: 0.9019 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8584 - acc: 0.7483 - val_loss: 0.9153 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8577 - acc: 0.7559 - val_loss: 0.9232 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8586 - acc: 0.7463 - val_loss: 0.9338 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8702 - acc: 0.7450 - val_loss: 0.9184 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8539 - acc: 0.7557 - val_loss: 0.9124 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8603 - acc: 0.7512 - val_loss: 0.9151 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8496 - acc: 0.7550 - val_loss: 0.9131 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8500 - acc: 0.7557 - val_loss: 0.9171 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8533 - acc: 0.7499 - val_loss: 0.9007 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8491 - acc: 0.7574 - val_loss: 0.9181 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8689 - acc: 0.7388 - val_loss: 0.9126 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8634 - acc: 0.7488 - val_loss: 0.9330 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8535 - acc: 0.7532 - val_loss: 0.9157 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8590 - acc: 0.7459 - val_loss: 0.9172 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8646 - acc: 0.7430 - val_loss: 0.9215 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8685 - acc: 0.7399 - val_loss: 0.8960 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8536 - acc: 0.7479 - val_loss: 0.9015 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8558 - acc: 0.7486 - val_loss: 0.9120 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8651 - acc: 0.7490 - val_loss: 0.9803 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8564 - acc: 0.7530 - val_loss: 0.9197 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8579 - acc: 0.7474 - val_loss: 0.9132 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8615 - acc: 0.7432 - val_loss: 0.9054 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8521 - acc: 0.7523 - val_loss: 0.9244 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8560 - acc: 0.7565 - val_loss: 0.9214 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8579 - acc: 0.7483 - val_loss: 0.8988 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8568 - acc: 0.7474 - val_loss: 0.8986 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8687 - acc: 0.7446 - val_loss: 0.9161 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8604 - acc: 0.7479 - val_loss: 0.9005 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8572 - acc: 0.7478 - val_loss: 0.8968 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8661 - acc: 0.7428 - val_loss: 0.8994 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8598 - acc: 0.7417 - val_loss: 0.9100 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8615 - acc: 0.7417 - val_loss: 0.9244 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8562 - acc: 0.7506 - val_loss: 0.9252 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8587 - acc: 0.7506 - val_loss: 0.9155 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8548 - acc: 0.7506 - val_loss: 0.9386 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8618 - acc: 0.7472 - val_loss: 0.9097 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8592 - acc: 0.7541 - val_loss: 0.9128 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8616 - acc: 0.7510 - val_loss: 0.9168 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8591 - acc: 0.7486 - val_loss: 0.9032 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8667 - acc: 0.7492 - val_loss: 0.9095 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8504 - acc: 0.7477 - val_loss: 0.9027 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8600 - acc: 0.7493 - val_loss: 0.9216 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8582 - acc: 0.7530 - val_loss: 0.9505 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8603 - acc: 0.7455 - val_loss: 0.9162 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8598 - acc: 0.7470 - val_loss: 0.9023 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8612 - acc: 0.7501 - val_loss: 0.9352 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8588 - acc: 0.7472 - val_loss: 0.9051 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8587 - acc: 0.7466 - val_loss: 0.9169 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8585 - acc: 0.7521 - val_loss: 0.9015 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8583 - acc: 0.7488 - val_loss: 0.8988 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8600 - acc: 0.7481 - val_loss: 0.8988 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8578 - acc: 0.7450 - val_loss: 0.9347 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8524 - acc: 0.7557 - val_loss: 0.8975 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8572 - acc: 0.7526 - val_loss: 0.9037 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8566 - acc: 0.7472 - val_loss: 0.9135 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8477 - acc: 0.7497 - val_loss: 0.9074 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8608 - acc: 0.7463 - val_loss: 0.9135 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8619 - acc: 0.7490 - val_loss: 0.8956 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8584 - acc: 0.7506 - val_loss: 0.9379 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8531 - acc: 0.7532 - val_loss: 0.9031 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8572 - acc: 0.7501 - val_loss: 0.9302 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8577 - acc: 0.7481 - val_loss: 0.9041 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8543 - acc: 0.7550 - val_loss: 0.9063 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8700 - acc: 0.7403 - val_loss: 0.9121 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8543 - acc: 0.7574 - val_loss: 0.9065 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8601 - acc: 0.7481 - val_loss: 0.9008 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 0.8649 - acc: 0.7450 - val_loss: 0.9299 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8591 - acc: 0.7515 - val_loss: 0.9209 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8541 - acc: 0.7503 - val_loss: 0.9221 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8544 - acc: 0.7521 - val_loss: 0.9023 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8524 - acc: 0.7490 - val_loss: 0.9141 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8654 - acc: 0.7428 - val_loss: 0.8928 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8567 - acc: 0.7541 - val_loss: 0.8955 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8605 - acc: 0.7481 - val_loss: 0.9163 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8645 - acc: 0.7545 - val_loss: 0.9383 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8679 - acc: 0.7468 - val_loss: 0.8981 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8495 - acc: 0.7557 - val_loss: 0.9143 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8591 - acc: 0.7539 - val_loss: 0.9078 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8585 - acc: 0.7537 - val_loss: 0.9039 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8412 - acc: 0.7541 - val_loss: 0.9073 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8596 - acc: 0.7481 - val_loss: 0.9006 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8487 - acc: 0.7581 - val_loss: 0.9280 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8554 - acc: 0.7514 - val_loss: 0.9087 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8522 - acc: 0.7499 - val_loss: 0.9025 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8574 - acc: 0.7486 - val_loss: 0.9021 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8615 - acc: 0.7534 - val_loss: 0.9151 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8575 - acc: 0.7554 - val_loss: 0.9035 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8568 - acc: 0.7459 - val_loss: 0.9157 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8553 - acc: 0.7508 - val_loss: 0.9009 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8640 - acc: 0.7508 - val_loss: 0.9387 - val_acc: 0.7301 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8551 - acc: 0.7497 - val_loss: 0.9168 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8668 - acc: 0.7439 - val_loss: 0.9022 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8537 - acc: 0.7554 - val_loss: 0.9031 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8601 - acc: 0.7490 - val_loss: 0.9019 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8627 - acc: 0.7463 - val_loss: 0.9284 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8503 - acc: 0.7537 - val_loss: 0.9098 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8652 - acc: 0.7537 - val_loss: 0.8995 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8568 - acc: 0.7459 - val_loss: 0.9126 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8638 - acc: 0.7450 - val_loss: 0.9245 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8596 - acc: 0.7479 - val_loss: 0.9182 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8490 - acc: 0.7550 - val_loss: 0.9020 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8514 - acc: 0.7499 - val_loss: 0.8944 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8594 - acc: 0.7512 - val_loss: 0.9049 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8582 - acc: 0.7477 - val_loss: 0.9068 - val_acc: 0.7340 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8650 - acc: 0.7468 - val_loss: 0.9132 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8638 - acc: 0.7470 - val_loss: 0.9045 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8588 - acc: 0.7470 - val_loss: 0.9006 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8515 - acc: 0.7510 - val_loss: 0.8992 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8603 - acc: 0.7510 - val_loss: 0.8966 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8631 - acc: 0.7494 - val_loss: 0.9522 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8595 - acc: 0.7506 - val_loss: 0.9396 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8540 - acc: 0.7503 - val_loss: 0.8912 - val_acc: 0.7456 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8578 - acc: 0.7519 - val_loss: 0.9026 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8605 - acc: 0.7508 - val_loss: 0.9231 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8650 - acc: 0.7428 - val_loss: 0.9051 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8587 - acc: 0.7497 - val_loss: 0.9098 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8625 - acc: 0.7474 - val_loss: 0.9200 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8565 - acc: 0.7507 - val_loss: 0.9120 - val_acc: 0.7379 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8631 - acc: 0.7521 - val_loss: 0.9374 - val_acc: 0.7262 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8537 - acc: 0.7565 - val_loss: 0.9280 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8620 - acc: 0.7477 - val_loss: 0.9093 - val_acc: 0.7320 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8532 - acc: 0.7534 - val_loss: 0.9161 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8573 - acc: 0.7492 - val_loss: 0.9029 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8629 - acc: 0.7435 - val_loss: 0.9233 - val_acc: 0.7359 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8648 - acc: 0.7479 - val_loss: 0.8995 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8546 - acc: 0.7492 - val_loss: 0.9155 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8592 - acc: 0.7472 - val_loss: 0.9331 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8622 - acc: 0.7477 - val_loss: 0.9085 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8467 - acc: 0.7557 - val_loss: 0.8981 - val_acc: 0.7398 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8515 - acc: 0.7486 - val_loss: 0.9083 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8541 - acc: 0.7499 - val_loss: 0.9088 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8606 - acc: 0.7530 - val_loss: 0.8822 - val_acc: 0.7476 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8620 - acc: 0.7488 - val_loss: 0.8975 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8512 - acc: 0.7512 - val_loss: 0.9126 - val_acc: 0.7417 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8571 - acc: 0.7512 - val_loss: 0.8935 - val_acc: 0.7437 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8553 - acc: 0.7510 - val_loss: 0.9059 - val_acc: 0.7282 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8579 - acc: 0.7508 - val_loss: 0.9078 - val_acc: 0.7495 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8563 - acc: 0.7532 - val_loss: 0.9015 - val_acc: 0.7515 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8610 - acc: 0.7488 - val_loss: 0.9079 - val_acc: 0.7340 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.save(\"wrn_model.h5\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djH4uwAnvkfb",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "079f2b6e-ad58-4fa5-c07e-aca64c4ff973"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f053822f-0ce6-49fa-c1f8-0810d6e606d2"
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 19ms/step - loss: 0.9118 - acc: 0.7435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9118168950080872, 0.7434554696083069]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QB8zFSSU7Qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "1b3dc3c2-f4ae-4d60-8c6d-7abf3aa05fcd"
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     || 87.9MB 120kB/s \n",
            "\u001b[K     || 3.1MB 40.9MB/s \n",
            "\u001b[K     || 501kB 44.0MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-9y8oajjf/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-9y8oajjf/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     || 163kB 6.6MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     || 51kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=f1ef3008478b66c6c172ff0a2f8c3083f29e0582c22cedf91c3ea9c516f6b3a8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cfvjxosq/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-24-67a2c783edbc>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bfZ4G8W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "\n",
        "logits_model = tf.keras.Model(wrn_16_2.input,wrn_16_2.layers[-1].output)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWIlakqVD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv = []\n",
        "epsilon_list = [0.003]\n",
        "for j in range(len(epsilon_list)):\n",
        "  epsilon = epsilon_list[j]\n",
        "  for i in range(len(X_test)):\n",
        "    random_index = i\n",
        "    original_image = X_test[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_test[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8XZJIGBkUku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0a01ae22-955a-4cfa-f577-16d3ec78720c"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 1.0164 - acc: 0.7086\n",
            "epsilon: 0.003 and test evalution : [1.016408920288086, 0.7085514664649963]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB2PbXrudUWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1095dfa1-7b14-4bd0-c803-233f6984270a"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.228538513183594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DCXV9Tc9B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "492ad00d-dbd5-462a-8cf8-917b151bf2f7"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 1.1244 - acc: 0.6614\n",
            "epsilon: 0.005 and test evalution : [1.124449372291565, 0.661431074142456]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGgsDCDodU_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3686bfaa-b695-4e0b-e6d4-352d3be899b4"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.79124450683594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Ah3eA2kYBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28105974-2f9c-475d-dfab-d5a402d223f0"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 1.3272 - acc: 0.5689\n",
            "epsilon: 0.01 and test evalution : [1.3272491693496704, 0.5689354538917542]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjfdNA70dVoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "823284d4-c58c-40dd-88a1-3857d942695c"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.77065086364746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xed10n0QmMqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b80f9c7d-4342-4724-d02d-ee56a1eb2b24"
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 1.7637 - acc: 0.4642\n",
            "epsilon: 0.02 and test evalution : [1.7636723518371582, 0.46422338485717773]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbqrQrSZdWX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "149bfd90-9342-47ea-a757-4796ebd05a8d"
      },
      "source": [
        "20*np.log10(np.linalg.norm(X_test)/np.linalg.norm(X_test-X_adv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.75005006790161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p3bOQqOO5yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adversarial_example(epsilon):\n",
        "  X_adv = []\n",
        "  for i in range(len(X_test)):\n",
        "    random_index = i\n",
        "    original_image = X_test[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_test[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "  return X_adv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOvOBknOPTHx",
        "colab_type": "text"
      },
      "source": [
        "**Mini batch training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDxVNgZvPRHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Adversarial Training \"\"\"\n",
        "\n",
        "import numpy as np\n",
        "class AdversarialTraining(object):\n",
        "    \"\"\"Adversarial Training  \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def train(self, model, pretrained_model, X_train, Y_train, X_val, Y_val, epochs, batch_size, epsilon_list):\n",
        "        \n",
        "        x_train, y_train = self.data_augmentation(X_train, Y_train, BS, pretrained_model, epsilon_list)\n",
        "        x_val, y_val = self.data_augmentation(X_val, Y_val, BS, pretrained_model, epsilon_list)\n",
        "        \n",
        "        hist = model.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=epochs,\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_data=(x_val, y_val),\n",
        "                   validation_steps=x_val.shape[0] // BS,)\n",
        "        return model\n",
        "    def mini_batch_train(self, model, X_train,y_train, x_val, y_val, BS, pretrained_model, epsilon):\n",
        "\n",
        "\n",
        "        hist = model.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=1,\n",
        "                   validation_data=(x_val, y_val),\n",
        "                   validation_steps=x_val.shape[0] // BS, shuffle = True)\n",
        "        \n",
        "        ### TODO ###\n",
        "        ## Save hist on file.###\n",
        "\n",
        "\n",
        "    def data_augmentation(self, X_train, Y_train, batch_size, pretrained_model, epsilon_list):\n",
        "      ### divide data 16,16,16,16 for 4 different epsilons and 64 is true image. ### \n",
        "        #start_index = self.data_iteration(X_train, batch_size)\n",
        "        first_half_end = int(len(X_train)/2)\n",
        "        second_half_end = int(len(X_train))\n",
        "        x_clean = X_train[0:first_half_end,:,:,:]\n",
        "        x_adv = self.get_adversarial(X_train[first_half_end:second_half_end,:,:,:], Y_train[first_half_end:second_half_end], epsilon_list)\n",
        "        x_mix = self.merge_data(x_clean, x_adv)\n",
        "        y_mix = Y_train[0:second_half_end]\n",
        "        ### TODO###\n",
        "        # Mixture data for 4 epsilon values\n",
        "\n",
        "        return x_mix, y_mix\n",
        "\n",
        "    def data_iteration(self, X_train, batch_size):\n",
        "        N = X_train.shape[0]\n",
        "        start = np.random.randint(0, N-batch_size)\n",
        "        return start\n",
        "\n",
        "    def merge_data(self, x_clean, x_adv):\n",
        "        x_mix = []\n",
        "        for i in range(len(x_clean)):\n",
        "          x_mix.append(x_clean[i])\n",
        "        for j in range(len(x_adv)):\n",
        "          x_mix.append(x_adv[j])\n",
        "        x_mix = np.array(x_mix)\n",
        "        print(x_mix.shape)\n",
        "\n",
        "        return x_mix\n",
        "\n",
        "\n",
        "    def get_adversarial(self, X_true, y_true, epsilon_list):\n",
        "\n",
        "        return self.adversarial_example(X_true, y_true, epsilon_list)\n",
        "\n",
        "    def adversarial_example(self, X_true, Y_true, epsilon_list):\n",
        "        size = len(X_true)\n",
        "        X_adv = []\n",
        "        interval = int(size/4)\n",
        "        index_list = [0,interval, interval*2, interval*3, size]\n",
        "        index = 0\n",
        "        for epsilon in epsilon_list:\n",
        "          print(index)\n",
        "          if index == 4:\n",
        "            break\n",
        "          x_true = X_true[index_list[index]:index_list[index+1],:,:,:]\n",
        "          y_true = Y_true[index_list[index]:index_list[index+1]]\n",
        "\n",
        "          index = index + 1\n",
        "\n",
        "          for i in range(len(x_true)):\n",
        "            random_index = i\n",
        "            original_image = x_true[random_index]\n",
        "            original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "            original_label = y_true[random_index]\n",
        "            original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "            adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf,y=original_label, targeted=False)\n",
        "            X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))\n",
        "          \n",
        "        X_adv = np.array(X_adv)\n",
        "        return X_adv\n"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW5vG0s9PAmw",
        "colab_type": "text"
      },
      "source": [
        "Adversarial Training Second Wide ResNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOvrHuAOuS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "71d2e3ce-4353-47e5-c75f-a291defd0ece"
      },
      "source": [
        "wrn_adv_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "#wrn_adv_16_2.summary()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdZqOMNvOqTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43c15464-ea74-4e73-cc52-d0d68c5311d8"
      },
      "source": [
        "wrn_adv_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xuZWpx-70n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon_list = [0.003,0.005,0.01,0.02]"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3373MWPvSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adversarial_training =  AdversarialTraining()"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i82EfjWHP2mv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69a0ac3a-e023-4579-96c8-0fd7506acf33"
      },
      "source": [
        "adversarial_training.train(wrn_adv_16_2, logits_model, X_train, y_train, X_val, y_val, 50, BS, epsilon_list)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "(4634, 32, 32, 1)\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "(515, 32, 32, 1)\n",
            "Epoch 1/50\n",
            "36/36 [==============================] - 4s 97ms/step - loss: 1.5970 - acc: 0.2980 - val_loss: 1.5647 - val_acc: 0.3320 - lr: 0.1000\n",
            "Epoch 2/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.5252 - acc: 0.3604 - val_loss: 1.4601 - val_acc: 0.3534 - lr: 0.1000\n",
            "Epoch 3/50\n",
            "36/36 [==============================] - 3s 86ms/step - loss: 1.4880 - acc: 0.3704 - val_loss: 1.4702 - val_acc: 0.3553 - lr: 0.1000\n",
            "Epoch 4/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.4690 - acc: 0.3806 - val_loss: 1.4531 - val_acc: 0.3631 - lr: 0.1000\n",
            "Epoch 5/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4490 - acc: 0.3855 - val_loss: 1.4210 - val_acc: 0.4466 - lr: 0.1000\n",
            "Epoch 6/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4349 - acc: 0.4037 - val_loss: 1.5277 - val_acc: 0.3631 - lr: 0.1000\n",
            "Epoch 7/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.4182 - acc: 0.4265 - val_loss: 1.4105 - val_acc: 0.4311 - lr: 0.1000\n",
            "Epoch 8/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.4079 - acc: 0.4434 - val_loss: 1.3614 - val_acc: 0.4680 - lr: 0.1000\n",
            "Epoch 9/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.3753 - acc: 0.4889 - val_loss: 2.0882 - val_acc: 0.3456 - lr: 0.1000\n",
            "Epoch 10/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.3720 - acc: 0.4996 - val_loss: 1.3378 - val_acc: 0.5204 - lr: 0.1000\n",
            "Epoch 11/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.3145 - acc: 0.5315 - val_loss: 1.3646 - val_acc: 0.4835 - lr: 0.1000\n",
            "Epoch 12/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2948 - acc: 0.5422 - val_loss: 1.2550 - val_acc: 0.5709 - lr: 0.1000\n",
            "Epoch 13/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2604 - acc: 0.5617 - val_loss: 1.5086 - val_acc: 0.4408 - lr: 0.1000\n",
            "Epoch 14/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2355 - acc: 0.5788 - val_loss: 1.4166 - val_acc: 0.5087 - lr: 0.1000\n",
            "Epoch 15/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.2121 - acc: 0.5881 - val_loss: 1.4509 - val_acc: 0.4874 - lr: 0.1000\n",
            "Epoch 16/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1882 - acc: 0.5985 - val_loss: 1.1897 - val_acc: 0.5864 - lr: 0.1000\n",
            "Epoch 17/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.1377 - acc: 0.6183 - val_loss: 1.2916 - val_acc: 0.5650 - lr: 0.1000\n",
            "Epoch 18/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1488 - acc: 0.6176 - val_loss: 1.8775 - val_acc: 0.4252 - lr: 0.1000\n",
            "Epoch 19/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.1171 - acc: 0.6391 - val_loss: 1.3887 - val_acc: 0.5359 - lr: 0.1000\n",
            "Epoch 20/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0752 - acc: 0.6531 - val_loss: 1.1956 - val_acc: 0.5864 - lr: 0.1000\n",
            "Epoch 21/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 1.0519 - acc: 0.6622 - val_loss: 1.2045 - val_acc: 0.6194 - lr: 0.1000\n",
            "Epoch 22/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 1.0350 - acc: 0.6671 - val_loss: 1.2078 - val_acc: 0.6136 - lr: 0.1000\n",
            "Epoch 23/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 1.0386 - acc: 0.6662 - val_loss: 1.3412 - val_acc: 0.5961 - lr: 0.1000\n",
            "Epoch 24/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9977 - acc: 0.6904 - val_loss: 1.2680 - val_acc: 0.5942 - lr: 0.1000\n",
            "Epoch 25/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9904 - acc: 0.6982 - val_loss: 1.3116 - val_acc: 0.6000 - lr: 0.1000\n",
            "Epoch 26/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9910 - acc: 0.6964 - val_loss: 1.1185 - val_acc: 0.6563 - lr: 0.1000\n",
            "Epoch 27/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9665 - acc: 0.7028 - val_loss: 1.0436 - val_acc: 0.6913 - lr: 0.1000\n",
            "Epoch 28/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9577 - acc: 0.7037 - val_loss: 1.1330 - val_acc: 0.6330 - lr: 0.1000\n",
            "Epoch 29/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9482 - acc: 0.7086 - val_loss: 1.1606 - val_acc: 0.6233 - lr: 0.1000\n",
            "Epoch 30/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.9350 - acc: 0.7144 - val_loss: 0.9852 - val_acc: 0.7184 - lr: 0.1000\n",
            "Epoch 31/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9190 - acc: 0.7186 - val_loss: 1.0046 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8824 - acc: 0.7417 - val_loss: 0.9653 - val_acc: 0.7282 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "36/36 [==============================] - 3s 85ms/step - loss: 0.8850 - acc: 0.7335 - val_loss: 0.9672 - val_acc: 0.7243 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8682 - acc: 0.7461 - val_loss: 0.9990 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8639 - acc: 0.7419 - val_loss: 0.9658 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8655 - acc: 0.7410 - val_loss: 0.9933 - val_acc: 0.6990 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8632 - acc: 0.7452 - val_loss: 0.9591 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8569 - acc: 0.7452 - val_loss: 0.9718 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8601 - acc: 0.7463 - val_loss: 0.9591 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8418 - acc: 0.7570 - val_loss: 0.9545 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8430 - acc: 0.7567 - val_loss: 0.9757 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8512 - acc: 0.7537 - val_loss: 0.9716 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8417 - acc: 0.7565 - val_loss: 1.0097 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8473 - acc: 0.7597 - val_loss: 0.9823 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8475 - acc: 0.7554 - val_loss: 0.9884 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8358 - acc: 0.7614 - val_loss: 0.9610 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8355 - acc: 0.7561 - val_loss: 0.9569 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8494 - acc: 0.7470 - val_loss: 0.9916 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8373 - acc: 0.7568 - val_loss: 1.0133 - val_acc: 0.6951 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "36/36 [==============================] - 3s 84ms/step - loss: 0.8353 - acc: 0.7563 - val_loss: 0.9777 - val_acc: 0.7126 - lr: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.training.Model at 0x7fb7777bf780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jltHWzqqt5W0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "025270a4-82a4-4226-f598-f373885251d9"
      },
      "source": [
        "wrn_adv_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 0.9052 - acc: 0.7469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9051674604415894, 0.7469459176063538]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYljaenf38Mf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "80ec8377-5928-4a7c-bda5-5e4e248f87ee"
      },
      "source": [
        "model.evaluate(X_adv,y_test)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 13ms/step - loss: 0.9039 - acc: 0.7312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.903908371925354, 0.7312390804290771]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    }
  ]
}