{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Tensorflow_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sefeoglu/AE_Parseval_Network/blob/master/src/notebooks/ResNet_Tensorflow_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczYDRrfFlDx",
        "colab_type": "text"
      },
      "source": [
        "# Wide ResNet 16_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWvd9YADGtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqbIFJTwXLH",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdSMgRjG8ex",
        "colab_type": "code",
        "outputId": "f61621b4-330d-4f56-8a26-4e39caff92d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0001\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    init = (32, 32,1)\n",
        "\n",
        "    wrn_16_2 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.5)\n",
        "\n",
        "    wrn_16_2.summary()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Wide Residual Network-16-2 created.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   144         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   4608        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   512         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9216        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 32)   0           add[0][0]                        \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 64)   18432       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36864       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   2048        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 64)   0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   36864       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16, 16, 64)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   256         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 64)   0           add_2[0][0]                      \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 128)    73728       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 128)    512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 128)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 128)    147456      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    8192        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 128)    0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 8, 8, 128)    512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 128)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 128)    147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 8, 128)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 128)    512         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 128)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 128)    147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 128)    0           add_4[0][0]                      \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 128)    0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            516         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 692,436\n",
            "Trainable params: 690,612\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffNo5x-Ft9Fe",
        "colab_type": "text"
      },
      "source": [
        "# Data Prepare and Processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqH742XcPQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRh7YDqiuqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('data_set.pickle', 'rb') as f:\n",
        "    x = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONi_4KtjjNE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train,X_test, y_test, X_val, y_val = x['X_train'], x['y_train'], x['X_test'], x['y_test'], x['X_val'], x['y_val']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNBI_SkvuzgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euxwMe2jIoX",
        "colab_type": "code",
        "outputId": "b8a89af9-b15e-428f-81f2-ba981804c810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import cv2\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(cv2.resize(row['crop'], (32,32)))\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBsNVDNu6Ku",
        "colab_type": "code",
        "outputId": "2266e79c-ba96-48fd-9247-86b41b5c9362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = new_data_X.astype('float32')\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQdrnTKuM8c",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf-dZOrvC0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = X[0].shape\n",
        "\n",
        "# transform data set\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eEHVf2Bu9xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "y_df = pd.DataFrame(Y_data, columns=['Label'])\n",
        "y_df['Encoded'] = labelencoder.fit_transform(y_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hwq9R2jruF",
        "colab_type": "code",
        "outputId": "fde82827-16be-4fb3-93a9-d908e5350f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "closed           1500\n",
              "open             1500\n",
              "partiallyOpen    1376\n",
              "notVisible       1346\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxAYuiEzj4Bp",
        "colab_type": "code",
        "outputId": "0289812a-6ff3-4727-9b99-fe5276b85a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "y_df['Encoded'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1500\n",
              "0    1500\n",
              "3    1376\n",
              "1    1346\n",
              "Name: Encoded, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdkpb2Jkqu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat = to_categorical(y_df['Encoded'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kif3Li9NuSnV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rghSgp3NvhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping\n",
        "import tensorflow\n",
        "\n",
        "EPOCHS = 200\n",
        "BS = 128\n",
        "sgd = SGD(lr=0.1, momentum=0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBnqXaiNwHGl",
        "colab_type": "code",
        "outputId": "b16631fb-0134-4d36-b027-71406fd505b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_16_2.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88yOqhbSwjPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 30:\n",
        "        return 0.1\n",
        "    elif epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch < 60:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpiWMEgRpWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-6r-Zvva5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs_QNHoEKji",
        "colab_type": "code",
        "outputId": "fa892c95-f59b-4890-b258-37075bdca70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = wrn_16_2.fit(generator.flow(X_train, y_train, batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   callbacks = [lr_scheduler],\n",
        "                   validation_data=(X_val, y_val),\n",
        "                   validation_steps=X_val.shape[0] // BS,)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 2s 68ms/step - loss: 1.5912 - acc: 0.3079 - val_loss: 1.5338 - val_acc: 0.3845 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 1.5084 - acc: 0.3673 - val_loss: 1.5161 - val_acc: 0.3883 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.4671 - acc: 0.3806 - val_loss: 1.5058 - val_acc: 0.3592 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.4622 - acc: 0.3877 - val_loss: 1.4645 - val_acc: 0.3689 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 1.4451 - acc: 0.3886 - val_loss: 1.4417 - val_acc: 0.4078 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 1.4361 - acc: 0.4099 - val_loss: 1.4039 - val_acc: 0.4039 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 1.4344 - acc: 0.4099 - val_loss: 1.3981 - val_acc: 0.4505 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.4151 - acc: 0.4332 - val_loss: 1.4019 - val_acc: 0.4330 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.4139 - acc: 0.4294 - val_loss: 1.3998 - val_acc: 0.4699 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.3825 - acc: 0.4747 - val_loss: 1.3987 - val_acc: 0.4951 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.3551 - acc: 0.5020 - val_loss: 1.2899 - val_acc: 0.5223 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.3314 - acc: 0.5198 - val_loss: 1.3237 - val_acc: 0.5010 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.3099 - acc: 0.5331 - val_loss: 1.2947 - val_acc: 0.5417 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.2855 - acc: 0.5446 - val_loss: 1.3478 - val_acc: 0.5476 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.2621 - acc: 0.5630 - val_loss: 1.2955 - val_acc: 0.5282 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.2303 - acc: 0.5701 - val_loss: 1.4759 - val_acc: 0.4621 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.2089 - acc: 0.5850 - val_loss: 1.1999 - val_acc: 0.5825 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.1771 - acc: 0.6056 - val_loss: 1.3145 - val_acc: 0.5670 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.1431 - acc: 0.6174 - val_loss: 1.2130 - val_acc: 0.5845 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.1260 - acc: 0.6238 - val_loss: 1.1231 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.0917 - acc: 0.6489 - val_loss: 1.0534 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 1.0725 - acc: 0.6538 - val_loss: 1.0893 - val_acc: 0.6641 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.0396 - acc: 0.6629 - val_loss: 1.0922 - val_acc: 0.6350 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 1.0536 - acc: 0.6662 - val_loss: 1.0401 - val_acc: 0.6699 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.0047 - acc: 0.6815 - val_loss: 1.4935 - val_acc: 0.5437 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 1.0099 - acc: 0.6798 - val_loss: 1.0320 - val_acc: 0.6680 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.9744 - acc: 0.6980 - val_loss: 1.0640 - val_acc: 0.6932 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.9593 - acc: 0.7146 - val_loss: 1.1328 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.9505 - acc: 0.7170 - val_loss: 1.1371 - val_acc: 0.6078 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.9407 - acc: 0.7139 - val_loss: 1.1338 - val_acc: 0.6388 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.9638 - acc: 0.7071 - val_loss: 0.9889 - val_acc: 0.6738 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.9144 - acc: 0.7215 - val_loss: 0.9745 - val_acc: 0.6816 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8803 - acc: 0.7388 - val_loss: 0.9443 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8747 - acc: 0.7386 - val_loss: 0.9778 - val_acc: 0.6854 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8726 - acc: 0.7364 - val_loss: 0.9442 - val_acc: 0.6951 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8611 - acc: 0.7499 - val_loss: 0.9387 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8572 - acc: 0.7523 - val_loss: 0.9608 - val_acc: 0.6951 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8567 - acc: 0.7517 - val_loss: 0.9741 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8578 - acc: 0.7474 - val_loss: 0.9332 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8642 - acc: 0.7412 - val_loss: 0.9338 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8487 - acc: 0.7494 - val_loss: 0.9500 - val_acc: 0.7049 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8499 - acc: 0.7514 - val_loss: 0.9302 - val_acc: 0.7146 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8411 - acc: 0.7641 - val_loss: 0.9384 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8444 - acc: 0.7565 - val_loss: 0.9229 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8385 - acc: 0.7554 - val_loss: 0.9453 - val_acc: 0.6913 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8468 - acc: 0.7483 - val_loss: 0.9243 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8381 - acc: 0.7639 - val_loss: 0.9422 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8302 - acc: 0.7670 - val_loss: 0.9260 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8323 - acc: 0.7594 - val_loss: 0.9286 - val_acc: 0.7107 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8428 - acc: 0.7506 - val_loss: 0.9285 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8340 - acc: 0.7645 - val_loss: 0.9897 - val_acc: 0.6971 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8243 - acc: 0.7676 - val_loss: 0.9230 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8348 - acc: 0.7643 - val_loss: 0.9213 - val_acc: 0.7204 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8373 - acc: 0.7639 - val_loss: 0.9375 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8343 - acc: 0.7590 - val_loss: 0.9235 - val_acc: 0.7165 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8294 - acc: 0.7628 - val_loss: 0.9303 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8221 - acc: 0.7714 - val_loss: 0.9181 - val_acc: 0.7126 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8336 - acc: 0.7594 - val_loss: 0.9377 - val_acc: 0.7087 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8339 - acc: 0.7579 - val_loss: 0.9423 - val_acc: 0.7029 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8313 - acc: 0.7641 - val_loss: 0.9168 - val_acc: 0.7068 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8313 - acc: 0.7583 - val_loss: 0.9417 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8246 - acc: 0.7623 - val_loss: 0.9405 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8249 - acc: 0.7652 - val_loss: 0.9506 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8241 - acc: 0.7659 - val_loss: 0.9181 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8272 - acc: 0.7605 - val_loss: 0.9207 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8141 - acc: 0.7681 - val_loss: 0.9283 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8274 - acc: 0.7599 - val_loss: 0.9297 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8339 - acc: 0.7608 - val_loss: 0.9153 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8251 - acc: 0.7581 - val_loss: 0.9418 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8240 - acc: 0.7688 - val_loss: 0.9262 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8280 - acc: 0.7563 - val_loss: 0.9073 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8290 - acc: 0.7597 - val_loss: 0.9291 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8273 - acc: 0.7597 - val_loss: 0.9139 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8287 - acc: 0.7685 - val_loss: 0.9161 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8256 - acc: 0.7654 - val_loss: 0.9311 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8280 - acc: 0.7654 - val_loss: 0.9392 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8313 - acc: 0.7634 - val_loss: 0.9394 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8280 - acc: 0.7688 - val_loss: 0.9591 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8218 - acc: 0.7617 - val_loss: 0.9345 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8207 - acc: 0.7730 - val_loss: 0.9279 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8247 - acc: 0.7630 - val_loss: 0.9194 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8275 - acc: 0.7641 - val_loss: 0.9232 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8426 - acc: 0.7605 - val_loss: 0.9111 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8287 - acc: 0.7597 - val_loss: 0.9232 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8341 - acc: 0.7663 - val_loss: 0.9165 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8197 - acc: 0.7650 - val_loss: 0.9398 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8293 - acc: 0.7585 - val_loss: 0.9891 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8143 - acc: 0.7670 - val_loss: 0.9211 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8279 - acc: 0.7614 - val_loss: 0.9337 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8353 - acc: 0.7565 - val_loss: 0.9234 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8332 - acc: 0.7654 - val_loss: 0.9234 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8223 - acc: 0.7679 - val_loss: 0.9226 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8347 - acc: 0.7588 - val_loss: 0.9361 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8280 - acc: 0.7632 - val_loss: 0.9118 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8270 - acc: 0.7648 - val_loss: 0.9020 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8198 - acc: 0.7621 - val_loss: 0.9205 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8268 - acc: 0.7632 - val_loss: 0.9338 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8240 - acc: 0.7659 - val_loss: 0.9289 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8211 - acc: 0.7734 - val_loss: 0.9232 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8251 - acc: 0.7645 - val_loss: 0.9172 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8200 - acc: 0.7652 - val_loss: 0.9360 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8360 - acc: 0.7614 - val_loss: 0.9206 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8294 - acc: 0.7572 - val_loss: 0.9187 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8281 - acc: 0.7588 - val_loss: 0.9282 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8323 - acc: 0.7590 - val_loss: 0.9303 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8243 - acc: 0.7645 - val_loss: 0.9344 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8279 - acc: 0.7590 - val_loss: 0.9165 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8290 - acc: 0.7593 - val_loss: 0.9198 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8335 - acc: 0.7652 - val_loss: 0.9320 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8270 - acc: 0.7656 - val_loss: 0.9206 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8253 - acc: 0.7628 - val_loss: 0.9143 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8304 - acc: 0.7661 - val_loss: 0.9271 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8267 - acc: 0.7614 - val_loss: 0.9454 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8358 - acc: 0.7614 - val_loss: 0.9312 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8292 - acc: 0.7605 - val_loss: 0.9223 - val_acc: 0.7184 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8276 - acc: 0.7608 - val_loss: 0.9095 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8169 - acc: 0.7692 - val_loss: 0.9211 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8246 - acc: 0.7668 - val_loss: 0.9332 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8328 - acc: 0.7590 - val_loss: 0.9287 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8272 - acc: 0.7683 - val_loss: 0.9236 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8205 - acc: 0.7663 - val_loss: 0.9171 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8270 - acc: 0.7599 - val_loss: 0.9338 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8214 - acc: 0.7634 - val_loss: 0.9256 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8333 - acc: 0.7621 - val_loss: 0.9163 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8302 - acc: 0.7614 - val_loss: 0.9324 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8242 - acc: 0.7610 - val_loss: 0.9220 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8231 - acc: 0.7630 - val_loss: 0.9264 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8317 - acc: 0.7628 - val_loss: 0.9171 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8274 - acc: 0.7668 - val_loss: 0.9575 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8273 - acc: 0.7610 - val_loss: 0.9302 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.8311 - acc: 0.7610 - val_loss: 0.9280 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8284 - acc: 0.7661 - val_loss: 0.9462 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8316 - acc: 0.7597 - val_loss: 0.9174 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8276 - acc: 0.7625 - val_loss: 0.9642 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8356 - acc: 0.7572 - val_loss: 0.9295 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8266 - acc: 0.7639 - val_loss: 0.9823 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8265 - acc: 0.7643 - val_loss: 0.9230 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8239 - acc: 0.7674 - val_loss: 0.9267 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8308 - acc: 0.7632 - val_loss: 0.9131 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8123 - acc: 0.7670 - val_loss: 0.9079 - val_acc: 0.7243 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8335 - acc: 0.7585 - val_loss: 0.9216 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8232 - acc: 0.7603 - val_loss: 0.9262 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8294 - acc: 0.7643 - val_loss: 0.9247 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8292 - acc: 0.7636 - val_loss: 0.9234 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8244 - acc: 0.7628 - val_loss: 0.9428 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.8211 - acc: 0.7685 - val_loss: 0.9214 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8247 - acc: 0.7650 - val_loss: 0.9380 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8297 - acc: 0.7639 - val_loss: 0.9464 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8363 - acc: 0.7630 - val_loss: 0.9602 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8180 - acc: 0.7690 - val_loss: 0.9632 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8290 - acc: 0.7632 - val_loss: 0.9235 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8231 - acc: 0.7579 - val_loss: 0.9254 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8307 - acc: 0.7583 - val_loss: 0.9144 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8351 - acc: 0.7619 - val_loss: 0.9287 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8164 - acc: 0.7634 - val_loss: 0.9115 - val_acc: 0.7223 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8269 - acc: 0.7601 - val_loss: 0.9296 - val_acc: 0.7204 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8316 - acc: 0.7614 - val_loss: 0.9222 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8230 - acc: 0.7605 - val_loss: 0.9228 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8204 - acc: 0.7696 - val_loss: 0.9373 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8224 - acc: 0.7581 - val_loss: 0.9298 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8260 - acc: 0.7565 - val_loss: 0.9285 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8204 - acc: 0.7614 - val_loss: 0.9215 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8267 - acc: 0.7623 - val_loss: 0.9044 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8298 - acc: 0.7599 - val_loss: 0.9232 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8188 - acc: 0.7668 - val_loss: 0.9146 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8170 - acc: 0.7719 - val_loss: 0.9354 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8178 - acc: 0.7727 - val_loss: 0.9295 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8261 - acc: 0.7661 - val_loss: 0.9175 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8245 - acc: 0.7579 - val_loss: 0.9163 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8220 - acc: 0.7665 - val_loss: 0.9282 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8290 - acc: 0.7639 - val_loss: 0.9344 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8200 - acc: 0.7696 - val_loss: 0.9258 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8274 - acc: 0.7641 - val_loss: 0.9269 - val_acc: 0.7126 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8255 - acc: 0.7619 - val_loss: 0.9363 - val_acc: 0.6990 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8245 - acc: 0.7665 - val_loss: 0.9208 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8296 - acc: 0.7619 - val_loss: 0.9551 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.8268 - acc: 0.7663 - val_loss: 0.9308 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8174 - acc: 0.7668 - val_loss: 0.9439 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8321 - acc: 0.7621 - val_loss: 0.9530 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8210 - acc: 0.7625 - val_loss: 0.9331 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8223 - acc: 0.7634 - val_loss: 0.9369 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8168 - acc: 0.7692 - val_loss: 0.9573 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8226 - acc: 0.7701 - val_loss: 0.9252 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8238 - acc: 0.7614 - val_loss: 0.9188 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8208 - acc: 0.7663 - val_loss: 0.9340 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8224 - acc: 0.7636 - val_loss: 0.9425 - val_acc: 0.7146 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8192 - acc: 0.7645 - val_loss: 0.9118 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8263 - acc: 0.7641 - val_loss: 0.9150 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8136 - acc: 0.7685 - val_loss: 0.9302 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 0.8287 - acc: 0.7694 - val_loss: 0.9249 - val_acc: 0.7087 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8258 - acc: 0.7572 - val_loss: 0.9346 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 2s 53ms/step - loss: 0.8186 - acc: 0.7619 - val_loss: 0.9553 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8261 - acc: 0.7654 - val_loss: 0.9155 - val_acc: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 0.8217 - acc: 0.7683 - val_loss: 0.9830 - val_acc: 0.7068 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 0.8233 - acc: 0.7632 - val_loss: 0.9197 - val_acc: 0.7165 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8243 - acc: 0.7663 - val_loss: 0.9325 - val_acc: 0.7107 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8287 - acc: 0.7592 - val_loss: 0.9196 - val_acc: 0.7029 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8278 - acc: 0.7601 - val_loss: 0.9174 - val_acc: 0.7010 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8208 - acc: 0.7727 - val_loss: 0.9326 - val_acc: 0.7049 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 0.8280 - acc: 0.7645 - val_loss: 0.9287 - val_acc: 0.7068 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI39Sx-kYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2.save(\"wrn_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djH4uwAnvkfb",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_quzDGwKGM",
        "colab_type": "code",
        "outputId": "493733e5-3c82-455e-e061-1769835a0f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE16jXuZw8xb",
        "colab_type": "code",
        "outputId": "a2c1102b-35f5-49f4-9348-84f4cf0bd35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "wrn_16_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8932 - acc: 0.7347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8932190537452698, 0.7347294688224792]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmZpcppX5u_C",
        "colab_type": "code",
        "outputId": "d8c5c032-3668-4397-cbc0-4ea363b2a2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "wrn_16_2.evaluate(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145/145 [==============================] - 1s 4ms/step - loss: 1.1210 - acc: 0.8323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1209561824798584, 0.8323262929916382]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDHJIheU8bm",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QB8zFSSU7Qy",
        "colab_type": "code",
        "outputId": "fbaa606d-6520-44c7-c329-5f9ce1a9e216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     || 87.9MB 52kB/s \n",
            "\u001b[K     || 501kB 43.5MB/s \n",
            "\u001b[K     || 3.1MB 37.1MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-ahbkk35p/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-ahbkk35p/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     || 163kB 2.6MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     || 51kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=371ac51e4c3e7e37696d6ede8cdd58b5d9cba16844d9fa736bc6fb3236da419c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xr27wh9n/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-15-67a2c783edbc>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bfZ4G8W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(wrn_16_2.input,wrn_16_2.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGWIlakqVD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv = []\n",
        "epsilon_list = [0.005]\n",
        "for j in range(len(epsilon_list)):\n",
        "  epsilon = epsilon_list[j]\n",
        "  for i in range(len(X_test)):\n",
        "    random_index = i\n",
        "    original_image = X_test[random_index]\n",
        "    original_image = tf.convert_to_tensor(original_image.reshape((1,32,32))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "    original_label = y_test[random_index]\n",
        "    original_label = np.reshape(np.argmax(original_label), (1,)).astype('int64')\n",
        "    adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "    X_adv.append(np.array(adv_example_targeted_label).reshape(32,32,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8XZJIGBkUku",
        "colab_type": "code",
        "outputId": "dfd252fb-4b4c-442f-ac05-23bde80e31dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8275 - acc: 0.2286\n",
            "epsilon: 0.1 and test evalution : [2.8275392055511475, 0.22862128913402557]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1DCXV9Tc9B0",
        "colab_type": "code",
        "outputId": "614e2c3d-267f-4b0e-ad53-e5c0325edf82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9418 - acc: 0.6876\n",
            "epsilon: 0.01 and test evalution : [0.9417540431022644, 0.687609076499939]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Ah3eA2kYBp",
        "colab_type": "code",
        "outputId": "ac46aff1-bc0f-4966-dff4-f00cb82b9843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8955 - acc: 0.7120\n",
            "epsilon: 0.005 and test evalution : [0.8954875469207764, 0.7120419144630432]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xed10n0QmMqr",
        "colab_type": "code",
        "outputId": "00afc29b-447f-47ac-c732-228734d1c644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "  X_adv = np.array(X_adv)\n",
        "  print(\"epsilon: {} and test evalution : {}\".format(epsilon,wrn_16_2.evaluate(X_adv,y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 12ms/step - loss: 1.0721 - acc: 0.6178\n",
            "epsilon: 0.015 and test evalution : [1.0720562934875488, 0.6178010702133179]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuWpwrKuwmsc",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfF0d5ePbXK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv = np.array(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5I9X-0mboqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df = pd.DataFrame(y_adv, columns=['Encoded'])\n",
        "y_adv_df['Encoded'] = labelencoder.fit_transform(y_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcxHP-bTcIwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_adv_df['Encoded'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1mGBoQbd46-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = []\n",
        "X_adv =my_data['image']\n",
        "for i in range(len(X_adv)):\n",
        "  a = np.array(X_adv[i])\n",
        "  X_new.append(a.reshape(68,100,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdE_WN8Ffgyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X)):\n",
        "  a = np.array(X[i])\n",
        "  X_new.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAnXO0Vfg1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_third = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jH1i_FMA2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a = np.array(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dackr68mMA0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_adv_a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UIXimpiKWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_new = []\n",
        "for j in range(0,2):\n",
        "  for i in range(len(y_cat)):\n",
        "    y_new.append(y_cat[i])\n",
        "y_third = np.array(y_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuRIuXcNiKY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_all, y_all = X_third, y_third"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXveP1Veo7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split( X_all,y_all, test_size = 0.33, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJjEg9qiI0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HibsOpTIcNq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q96wjHqxeTJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")\n",
        "BS_adv= 100\n",
        "EPOCHS_adv = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jewqs8yxlnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch_train(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.1\n",
        "    elif epoch <20:\n",
        "        return 0.1/2.0\n",
        "    elif epoch < 30:\n",
        "        return 0.1/2.0**2\n",
        "    elif epoch < 40:\n",
        "        return 0.1/2.0**3\n",
        "    else:\n",
        "        return 0.1/2.0**4\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler_train = LearningRateScheduler(lr_sch_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FIn8khEd45J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "hist = wrn_16_2_adv.fit_generator(generator.flow(X_train_adv, y_train_adv, batch_size=BS_adv), steps_per_epoch=len(X_train_adv) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test_adv, y_test_adv),\n",
        "                   validation_steps=X_test_adv.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qXnteSOpFZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.save(\"model_adv_wrn_tensor_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeetxZrNv9oM",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S5IjLivpMbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcU_6z90QSJ",
        "colab_type": "text"
      },
      "source": [
        "**CleanExperiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5qUE6j0JUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4p2TUIj0csZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQljdkd0he9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_clean = wrn_16_2_clean.fit_generator(generator.flow(X_train, y_train, batch_size=BS_adv), steps_per_epoch=len(X_train) // BS_adv, epochs=EPOCHS_adv,\n",
        "                   callbacks=[lr_scheduler_train],\n",
        "                   validation_data=(X_test, y_test),\n",
        "                   validation_steps=X_test.shape[0] // BS_adv,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1acrchBU185p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.save(\"model_adv_train_clean_dropout.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9hLRXbmwETE",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pgU_KsH0yVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = hist_clean\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"wrn_tensor.png\")\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig(\"deneme.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCKONCZ0Jzfi",
        "colab_type": "text"
      },
      "source": [
        "**Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgpFgWbKeR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiqvES18c-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHVWy96Llce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqj_Ax7MI4SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXT3YD6iLl0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_adv.evaluate(X_test_adv,y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fKhEMXgKAnZ",
        "colab_type": "text"
      },
      "source": [
        "**Non_Adversarial_Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouj6OqTD8VdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfkUSeV6KHp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_train_adv,y_train_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFJl2D4Hbxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gJh7MDHChHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_adv_a,y_cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZuONcAeAwQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrn_16_2_clean.evaluate(X_test_adv, y_test_adv)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}