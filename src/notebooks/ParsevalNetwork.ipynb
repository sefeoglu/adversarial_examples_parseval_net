{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ParsevalNetwork.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "esXS1STy_O_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nX1rD7_O_t",
        "colab_type": "code",
        "outputId": "5d8381e7-1ef1-4920-c7b1-533266fd9b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def read_data():\n",
        "    with open(\"data.pz\", 'rb') as file_:\n",
        "        with gzip.GzipFile(fileobj=file_) as gzf:\n",
        "            data = pickle.load(gzf, encoding='latin1', fix_imports=True)\n",
        "    return data\n",
        "data = read_data()\n",
        "new_data_X = []\n",
        "Y_data = []\n",
        "for row in data:\n",
        "    new_data_X.append(row['crop'])\n",
        "    Y_data.append(row['label'])\n",
        "new_data_X = np.array(new_data_X)\n",
        "new_data_X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5722, 68, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmyV1MMm_O_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_data_X, Y_data, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRS393n_O_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCu-tWhd_O_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# creating initial dataframe\n",
        "\n",
        "y_train_df = pd.DataFrame(y_train, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_train_df['New'] = labelencoder.fit_transform(y_train_df['Label'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Label'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "y_test_df['New'] = labelencoder.fit_transform(y_test_df['Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5CHhcF_PAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02f1ff5a-c8ab-45f9-ed50-a82933c7a36e"
      },
      "source": [
        "from keras import backend as K\n",
        "img_rows, img_cols = X_train[0].shape\n",
        "\n",
        "\n",
        "# transform data set\n",
        "if K.common.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3g_vzsy_ndF",
        "colab_type": "text"
      },
      "source": [
        "**Parseval Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sllEBqMW_tEz",
        "colab_type": "text"
      },
      "source": [
        "**Constrait**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN76FYUZ_3YA",
        "colab_type": "code",
        "outputId": "a8ec15ab-e4dd-4ff5-ac38-135246e2eecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "weight_decay = 0.0005\n",
        "\n",
        "\n",
        "def initial_conv(input):\n",
        "  \n",
        "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def expand_conv(init, base, k, strides=(1, 1)):\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='Orthogonal', kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(init)\n",
        "\n",
        "    m = Add()([x, skip])\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def conv1_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv2:channel:  {}\".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    print(\"conv3 channel_axis:{} \".format(channel_axis))\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='Orthogonal',\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      use_bias=False)(x)\n",
        "\n",
        "    m = Add()([init, x])\n",
        "    return m\n",
        "\n",
        "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
        "    \"\"\"\n",
        "    Creates a Wide Residual Network with specified parameters\n",
        "\n",
        "    :param input: Input Keras object\n",
        "    :param nb_classes: Number of output classes\n",
        "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
        "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "    :param k: Width of the network.\n",
        "    :param dropout: Adds dropout if value is greater than 0.0\n",
        "    :param verbose: Debug info to describe created WRN\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    ip = Input(shape=input_dim)\n",
        "\n",
        "    x = initial_conv(ip)\n",
        "    nb_conv = 4\n",
        "\n",
        "    x = expand_conv(x, 16, k)\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv1_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv2_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
        "    nb_conv += 2\n",
        "\n",
        "    for i in range(N - 1):\n",
        "        x = conv3_block(x, k, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n",
        "\n",
        "    model = Model(ip, x)\n",
        "\n",
        "    if verbose: print(\"Parseval Residual Network-%d-%d created.\" % (nb_conv, k))\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from tensorflow.keras.utils import plot_model\n",
        "    from tensorflow.keras.layers import Input\n",
        "    from tensorflow.keras.models import Model\n",
        "\n",
        "    init = (68, 100,1)\n",
        "\n",
        "    wrn_28_10 = create_wide_residual_network(init, nb_classes=4, N=2, k=2, dropout=0.0)\n",
        "\n",
        "    wrn_28_10.summary()\n",
        "\n",
        "   # plot_model(wrn_28_10, \"WRN-16-2.png\", show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2:channel:  -1\n",
            "conv3 channel_axis:-1 \n",
            "Parseval Residual Network-16-2 created.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 68, 100, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 68, 100, 16)  144         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 68, 100, 16)  64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 68, 100, 16)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 68, 100, 32)  4608        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 68, 100, 32)  128         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 68, 100, 32)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 68, 100, 32)  9216        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 68, 100, 32)  512         activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 68, 100, 32)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 68, 100, 32)  128         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 68, 100, 32)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 68, 100, 32)  9216        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 68, 100, 32)  128         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 68, 100, 32)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 68, 100, 32)  9216        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 68, 100, 32)  0           add_6[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 68, 100, 32)  128         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 68, 100, 32)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 34, 50, 64)   18432       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 34, 50, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 34, 50, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 34, 50, 64)   36864       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 34, 50, 64)   2048        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 34, 50, 64)   0           conv2d_23[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 34, 50, 64)   256         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 34, 50, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 34, 50, 64)   36864       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 34, 50, 64)   256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 34, 50, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 34, 50, 64)   36864       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 34, 50, 64)   0           add_8[0][0]                      \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 34, 50, 64)   256         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 34, 50, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 17, 25, 128)  73728       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 17, 25, 128)  512         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 17, 25, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 17, 25, 128)  147456      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 25, 128)  8192        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 17, 25, 128)  0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 17, 25, 128)  512         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 17, 25, 128)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 25, 128)  147456      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 17, 25, 128)  512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 17, 25, 128)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 25, 128)  147456      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 17, 25, 128)  0           add_10[0][0]                     \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 17, 25, 128)  512         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 17, 25, 128)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 2, 3, 128)    0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 768)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            3076        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 694,996\n",
            "Trainable params: 693,172\n",
            "Non-trainable params: 1,824\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxyMKoeaBqPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.callbacks as callbacks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiFrat1Bv1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200\n",
        "BS = 128\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ygMFWH8Bzfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUvPL0dB48O",
        "colab_type": "code",
        "outputId": "da5ff43e-3384-4419-de1c-101a6af5a60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrn_28_10.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
        "print(\"Finished compiling\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished compiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrJ7xy1Q5rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
        "                               width_shift_range=5./32,\n",
        "                               height_shift_range=5./32,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4EpGTMG9jeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_sch(epoch):\n",
        "    if epoch < 60:\n",
        "        return 0.1\n",
        "    elif epoch < 120:\n",
        "        return 0.02\n",
        "    elif epoch < 160:\n",
        "        return 0.004\n",
        "    else:\n",
        "        return 0.0008\n",
        "\n",
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_sch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bu78FGi9jhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0CbPY_24ns",
        "colab_type": "code",
        "outputId": "5698535b-716a-4044-fa01-50ed04793555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "hist = wrn_28_10.fit_generator(generator.flow(X_train, to_categorical(y_train_df['New']), batch_size=BS), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS,\n",
        "                   validation_data=(X_test, to_categorical(y_test_df['New'])), callbacks = [lr_scheduler],\n",
        "                   validation_steps=X_test.shape[0] // BS,)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-885b3a196f9b>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/200\n",
            "29/29 [==============================] - 16s 569ms/step - loss: 1.8403 - acc: 0.3192 - val_loss: 1.7881 - val_acc: 0.3843 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 16s 559ms/step - loss: 1.7576 - acc: 0.3749 - val_loss: 1.6923 - val_acc: 0.4029 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 15s 509ms/step - loss: 1.7173 - acc: 0.3989 - val_loss: 1.6509 - val_acc: 0.4389 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 1.6703 - acc: 0.4084 - val_loss: 1.6039 - val_acc: 0.4468 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 1.6186 - acc: 0.4354 - val_loss: 1.5530 - val_acc: 0.4717 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 1.5609 - acc: 0.4737 - val_loss: 1.4949 - val_acc: 0.5050 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 1.4866 - acc: 0.5012 - val_loss: 1.6719 - val_acc: 0.4653 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 1.4414 - acc: 0.5285 - val_loss: 1.4135 - val_acc: 0.5363 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 1.3936 - acc: 0.5463 - val_loss: 1.3387 - val_acc: 0.5839 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 1.3297 - acc: 0.5722 - val_loss: 1.2743 - val_acc: 0.6003 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 1.2823 - acc: 0.5873 - val_loss: 1.3554 - val_acc: 0.5686 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 1.2488 - acc: 0.6008 - val_loss: 1.1947 - val_acc: 0.6416 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 1.2025 - acc: 0.6294 - val_loss: 1.4595 - val_acc: 0.5363 - lr: 0.1000\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 1.1777 - acc: 0.6294 - val_loss: 1.2458 - val_acc: 0.6347 - lr: 0.1000\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 1.1529 - acc: 0.6424 - val_loss: 1.1616 - val_acc: 0.6458 - lr: 0.1000\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 1.0980 - acc: 0.6623 - val_loss: 1.1094 - val_acc: 0.6564 - lr: 0.1000\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 1.0691 - acc: 0.6726 - val_loss: 1.0969 - val_acc: 0.6644 - lr: 0.1000\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 1.0274 - acc: 0.7004 - val_loss: 0.9636 - val_acc: 0.7231 - lr: 0.1000\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.9768 - acc: 0.7080 - val_loss: 1.0264 - val_acc: 0.7035 - lr: 0.1000\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.9711 - acc: 0.7155 - val_loss: 1.0626 - val_acc: 0.6797 - lr: 0.1000\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.9353 - acc: 0.7233 - val_loss: 0.9610 - val_acc: 0.7205 - lr: 0.1000\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.9692 - acc: 0.7042 - val_loss: 1.1046 - val_acc: 0.6570 - lr: 0.1000\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.9348 - acc: 0.7169 - val_loss: 1.0626 - val_acc: 0.6776 - lr: 0.1000\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.8848 - acc: 0.7430 - val_loss: 0.8949 - val_acc: 0.7337 - lr: 0.1000\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.8849 - acc: 0.7455 - val_loss: 0.9219 - val_acc: 0.7295 - lr: 0.1000\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.8458 - acc: 0.7619 - val_loss: 0.9391 - val_acc: 0.7395 - lr: 0.1000\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.8673 - acc: 0.7439 - val_loss: 0.9145 - val_acc: 0.7279 - lr: 0.1000\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.8207 - acc: 0.7628 - val_loss: 0.9721 - val_acc: 0.7364 - lr: 0.1000\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.7909 - acc: 0.7714 - val_loss: 0.8717 - val_acc: 0.7528 - lr: 0.1000\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.7841 - acc: 0.7714 - val_loss: 0.8492 - val_acc: 0.7522 - lr: 0.1000\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.8026 - acc: 0.7722 - val_loss: 0.9719 - val_acc: 0.6924 - lr: 0.1000\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.7681 - acc: 0.7800 - val_loss: 1.0149 - val_acc: 0.7200 - lr: 0.1000\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.7479 - acc: 0.7868 - val_loss: 0.9236 - val_acc: 0.7184 - lr: 0.1000\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.7619 - acc: 0.7919 - val_loss: 0.8726 - val_acc: 0.7522 - lr: 0.1000\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.7482 - acc: 0.7873 - val_loss: 0.9806 - val_acc: 0.7168 - lr: 0.1000\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.7376 - acc: 0.7935 - val_loss: 0.8260 - val_acc: 0.7639 - lr: 0.1000\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.7130 - acc: 0.7984 - val_loss: 0.8609 - val_acc: 0.7390 - lr: 0.1000\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.7214 - acc: 0.8065 - val_loss: 0.9265 - val_acc: 0.7253 - lr: 0.1000\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.7388 - acc: 0.7852 - val_loss: 0.8278 - val_acc: 0.7655 - lr: 0.1000\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.6836 - acc: 0.8054 - val_loss: 0.8856 - val_acc: 0.7528 - lr: 0.1000\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.7126 - acc: 0.8027 - val_loss: 0.8138 - val_acc: 0.7724 - lr: 0.1000\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.6572 - acc: 0.8275 - val_loss: 0.8083 - val_acc: 0.7697 - lr: 0.1000\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.6437 - acc: 0.8300 - val_loss: 0.8799 - val_acc: 0.7401 - lr: 0.1000\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.6770 - acc: 0.8208 - val_loss: 1.1375 - val_acc: 0.7035 - lr: 0.1000\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.7101 - acc: 0.8011 - val_loss: 0.9003 - val_acc: 0.7321 - lr: 0.1000\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.6668 - acc: 0.8248 - val_loss: 0.8166 - val_acc: 0.7655 - lr: 0.1000\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.6477 - acc: 0.8265 - val_loss: 0.8529 - val_acc: 0.7623 - lr: 0.1000\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.6503 - acc: 0.8313 - val_loss: 0.9075 - val_acc: 0.7528 - lr: 0.1000\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.6336 - acc: 0.8329 - val_loss: 0.7975 - val_acc: 0.7861 - lr: 0.1000\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.6525 - acc: 0.8275 - val_loss: 0.8855 - val_acc: 0.7517 - lr: 0.1000\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.6731 - acc: 0.8175 - val_loss: 0.7978 - val_acc: 0.7867 - lr: 0.1000\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.6328 - acc: 0.8367 - val_loss: 0.8488 - val_acc: 0.7692 - lr: 0.1000\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.6340 - acc: 0.8348 - val_loss: 0.9125 - val_acc: 0.7406 - lr: 0.1000\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.6302 - acc: 0.8375 - val_loss: 0.8960 - val_acc: 0.7687 - lr: 0.1000\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.6058 - acc: 0.8486 - val_loss: 0.8795 - val_acc: 0.7761 - lr: 0.1000\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.5802 - acc: 0.8602 - val_loss: 0.8521 - val_acc: 0.7718 - lr: 0.1000\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.5687 - acc: 0.8688 - val_loss: 0.9483 - val_acc: 0.7618 - lr: 0.1000\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.6341 - acc: 0.8410 - val_loss: 0.8018 - val_acc: 0.7946 - lr: 0.1000\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.5558 - acc: 0.8737 - val_loss: 0.8588 - val_acc: 0.7824 - lr: 0.1000\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.5666 - acc: 0.8731 - val_loss: 0.9410 - val_acc: 0.7517 - lr: 0.1000\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.5716 - acc: 0.8648 - val_loss: 0.8328 - val_acc: 0.7988 - lr: 0.0200\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.4566 - acc: 0.9185 - val_loss: 0.7899 - val_acc: 0.8158 - lr: 0.0200\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.4094 - acc: 0.9358 - val_loss: 0.7719 - val_acc: 0.8205 - lr: 0.0200\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.3910 - acc: 0.9363 - val_loss: 0.8249 - val_acc: 0.8115 - lr: 0.0200\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.3674 - acc: 0.9520 - val_loss: 0.7881 - val_acc: 0.8152 - lr: 0.0200\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.3548 - acc: 0.9506 - val_loss: 0.8108 - val_acc: 0.8205 - lr: 0.0200\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.3535 - acc: 0.9501 - val_loss: 0.8032 - val_acc: 0.8237 - lr: 0.0200\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.3423 - acc: 0.9547 - val_loss: 0.8033 - val_acc: 0.8227 - lr: 0.0200\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.3278 - acc: 0.9601 - val_loss: 0.8483 - val_acc: 0.8179 - lr: 0.0200\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.3222 - acc: 0.9609 - val_loss: 0.8389 - val_acc: 0.8163 - lr: 0.0200\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.3137 - acc: 0.9628 - val_loss: 0.8147 - val_acc: 0.8285 - lr: 0.0200\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.3165 - acc: 0.9646 - val_loss: 0.9117 - val_acc: 0.8084 - lr: 0.0200\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.3045 - acc: 0.9676 - val_loss: 0.8540 - val_acc: 0.8216 - lr: 0.0200\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.3063 - acc: 0.9625 - val_loss: 0.8666 - val_acc: 0.8068 - lr: 0.0200\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2949 - acc: 0.9663 - val_loss: 0.8674 - val_acc: 0.8258 - lr: 0.0200\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2958 - acc: 0.9625 - val_loss: 0.8535 - val_acc: 0.8264 - lr: 0.0200\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2826 - acc: 0.9719 - val_loss: 0.9152 - val_acc: 0.8158 - lr: 0.0200\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2862 - acc: 0.9663 - val_loss: 0.8977 - val_acc: 0.8190 - lr: 0.0200\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2920 - acc: 0.9633 - val_loss: 0.8647 - val_acc: 0.8121 - lr: 0.0200\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2716 - acc: 0.9733 - val_loss: 0.9128 - val_acc: 0.8221 - lr: 0.0200\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2735 - acc: 0.9722 - val_loss: 0.8717 - val_acc: 0.8205 - lr: 0.0200\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2643 - acc: 0.9762 - val_loss: 0.9147 - val_acc: 0.8062 - lr: 0.0200\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2601 - acc: 0.9754 - val_loss: 0.9667 - val_acc: 0.8152 - lr: 0.0200\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2769 - acc: 0.9652 - val_loss: 0.8617 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.2640 - acc: 0.9725 - val_loss: 0.9265 - val_acc: 0.8174 - lr: 0.0200\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2583 - acc: 0.9757 - val_loss: 0.8947 - val_acc: 0.8205 - lr: 0.0200\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.2481 - acc: 0.9787 - val_loss: 0.8912 - val_acc: 0.8248 - lr: 0.0200\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.2557 - acc: 0.9744 - val_loss: 0.8780 - val_acc: 0.8211 - lr: 0.0200\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2488 - acc: 0.9746 - val_loss: 0.9314 - val_acc: 0.8195 - lr: 0.0200\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2422 - acc: 0.9781 - val_loss: 0.9293 - val_acc: 0.8115 - lr: 0.0200\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2420 - acc: 0.9827 - val_loss: 0.8930 - val_acc: 0.8205 - lr: 0.0200\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2312 - acc: 0.9825 - val_loss: 0.9062 - val_acc: 0.8248 - lr: 0.0200\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2361 - acc: 0.9798 - val_loss: 0.9904 - val_acc: 0.8195 - lr: 0.0200\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.2453 - acc: 0.9752 - val_loss: 0.9374 - val_acc: 0.8248 - lr: 0.0200\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2351 - acc: 0.9798 - val_loss: 0.9415 - val_acc: 0.8221 - lr: 0.0200\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2401 - acc: 0.9771 - val_loss: 0.9056 - val_acc: 0.8211 - lr: 0.0200\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2303 - acc: 0.9803 - val_loss: 0.9030 - val_acc: 0.8359 - lr: 0.0200\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2225 - acc: 0.9833 - val_loss: 0.9122 - val_acc: 0.8216 - lr: 0.0200\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.2308 - acc: 0.9800 - val_loss: 0.9735 - val_acc: 0.8216 - lr: 0.0200\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2323 - acc: 0.9789 - val_loss: 0.9929 - val_acc: 0.8126 - lr: 0.0200\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2281 - acc: 0.9789 - val_loss: 0.9681 - val_acc: 0.8242 - lr: 0.0200\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.2332 - acc: 0.9784 - val_loss: 1.0473 - val_acc: 0.8089 - lr: 0.0200\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2349 - acc: 0.9760 - val_loss: 0.9110 - val_acc: 0.8232 - lr: 0.0200\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2245 - acc: 0.9792 - val_loss: 0.9274 - val_acc: 0.8179 - lr: 0.0200\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.2376 - acc: 0.9717 - val_loss: 0.9279 - val_acc: 0.8269 - lr: 0.0200\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2409 - acc: 0.9711 - val_loss: 0.9536 - val_acc: 0.8211 - lr: 0.0200\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2330 - acc: 0.9754 - val_loss: 0.9508 - val_acc: 0.8227 - lr: 0.0200\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2165 - acc: 0.9822 - val_loss: 0.9726 - val_acc: 0.8152 - lr: 0.0200\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2146 - acc: 0.9827 - val_loss: 0.8985 - val_acc: 0.8295 - lr: 0.0200\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2204 - acc: 0.9784 - val_loss: 0.9666 - val_acc: 0.8121 - lr: 0.0200\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2165 - acc: 0.9811 - val_loss: 0.9396 - val_acc: 0.8227 - lr: 0.0200\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2098 - acc: 0.9843 - val_loss: 1.0784 - val_acc: 0.7983 - lr: 0.0200\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2168 - acc: 0.9814 - val_loss: 0.9440 - val_acc: 0.8126 - lr: 0.0200\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2129 - acc: 0.9822 - val_loss: 0.9049 - val_acc: 0.8200 - lr: 0.0200\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.2182 - acc: 0.9830 - val_loss: 0.9647 - val_acc: 0.8237 - lr: 0.0200\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.2140 - acc: 0.9792 - val_loss: 0.9845 - val_acc: 0.8137 - lr: 0.0200\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.2005 - acc: 0.9854 - val_loss: 0.9728 - val_acc: 0.8158 - lr: 0.0200\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1950 - acc: 0.9887 - val_loss: 0.9807 - val_acc: 0.8184 - lr: 0.0200\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1907 - acc: 0.9881 - val_loss: 0.9534 - val_acc: 0.8290 - lr: 0.0200\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1861 - acc: 0.9906 - val_loss: 0.9195 - val_acc: 0.8311 - lr: 0.0200\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1904 - acc: 0.9876 - val_loss: 0.9329 - val_acc: 0.8359 - lr: 0.0040\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1743 - acc: 0.9949 - val_loss: 0.9395 - val_acc: 0.8338 - lr: 0.0040\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.1710 - acc: 0.9951 - val_loss: 0.8820 - val_acc: 0.8354 - lr: 0.0040\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1681 - acc: 0.9968 - val_loss: 0.9210 - val_acc: 0.8401 - lr: 0.0040\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1670 - acc: 0.9962 - val_loss: 0.9255 - val_acc: 0.8317 - lr: 0.0040\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1664 - acc: 0.9962 - val_loss: 0.9094 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1635 - acc: 0.9976 - val_loss: 0.8664 - val_acc: 0.8417 - lr: 0.0040\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1597 - acc: 0.9987 - val_loss: 0.9163 - val_acc: 0.8417 - lr: 0.0040\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1621 - acc: 0.9976 - val_loss: 0.9332 - val_acc: 0.8332 - lr: 0.0040\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1590 - acc: 0.9970 - val_loss: 0.8997 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1604 - acc: 0.9965 - val_loss: 0.9021 - val_acc: 0.8433 - lr: 0.0040\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1591 - acc: 0.9987 - val_loss: 0.9321 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1599 - acc: 0.9978 - val_loss: 0.9127 - val_acc: 0.8396 - lr: 0.0040\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1569 - acc: 0.9984 - val_loss: 0.9527 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1568 - acc: 0.9984 - val_loss: 0.9401 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1580 - acc: 0.9978 - val_loss: 0.9277 - val_acc: 0.8412 - lr: 0.0040\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1552 - acc: 0.9984 - val_loss: 0.9178 - val_acc: 0.8375 - lr: 0.0040\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1558 - acc: 0.9978 - val_loss: 0.9391 - val_acc: 0.8338 - lr: 0.0040\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1553 - acc: 0.9984 - val_loss: 0.9173 - val_acc: 0.8433 - lr: 0.0040\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1550 - acc: 0.9976 - val_loss: 0.9332 - val_acc: 0.8380 - lr: 0.0040\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1517 - acc: 0.9992 - val_loss: 0.9293 - val_acc: 0.8359 - lr: 0.0040\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1534 - acc: 0.9987 - val_loss: 0.9257 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1524 - acc: 0.9992 - val_loss: 0.9496 - val_acc: 0.8343 - lr: 0.0040\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1524 - acc: 0.9995 - val_loss: 0.9180 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1552 - acc: 0.9976 - val_loss: 0.9187 - val_acc: 0.8375 - lr: 0.0040\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1520 - acc: 0.9989 - val_loss: 0.9293 - val_acc: 0.8375 - lr: 0.0040\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1510 - acc: 0.9992 - val_loss: 0.9194 - val_acc: 0.8364 - lr: 0.0040\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1489 - acc: 0.9995 - val_loss: 0.9055 - val_acc: 0.8401 - lr: 0.0040\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1501 - acc: 0.9989 - val_loss: 0.9089 - val_acc: 0.8385 - lr: 0.0040\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1515 - acc: 0.9981 - val_loss: 0.9288 - val_acc: 0.8354 - lr: 0.0040\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.1505 - acc: 0.9987 - val_loss: 0.9241 - val_acc: 0.8391 - lr: 0.0040\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1482 - acc: 0.9995 - val_loss: 0.9143 - val_acc: 0.8359 - lr: 0.0040\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.1479 - acc: 0.9992 - val_loss: 0.8994 - val_acc: 0.8407 - lr: 0.0040\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1478 - acc: 0.9987 - val_loss: 0.9018 - val_acc: 0.8359 - lr: 0.0040\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1494 - acc: 0.9978 - val_loss: 0.9479 - val_acc: 0.8380 - lr: 0.0040\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1488 - acc: 0.9987 - val_loss: 0.9349 - val_acc: 0.8380 - lr: 0.0040\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1475 - acc: 0.9989 - val_loss: 0.9491 - val_acc: 0.8348 - lr: 0.0040\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1457 - acc: 1.0000 - val_loss: 0.9552 - val_acc: 0.8348 - lr: 0.0040\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1462 - acc: 0.9995 - val_loss: 0.8946 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1470 - acc: 0.9978 - val_loss: 0.9093 - val_acc: 0.8370 - lr: 0.0040\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1444 - acc: 0.9995 - val_loss: 0.9553 - val_acc: 0.8354 - lr: 8.0000e-04\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1462 - acc: 0.9992 - val_loss: 0.9237 - val_acc: 0.8380 - lr: 8.0000e-04\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1445 - acc: 0.9995 - val_loss: 0.9411 - val_acc: 0.8385 - lr: 8.0000e-04\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1465 - acc: 0.9981 - val_loss: 0.9321 - val_acc: 0.8364 - lr: 8.0000e-04\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1442 - acc: 0.9997 - val_loss: 0.9049 - val_acc: 0.8396 - lr: 8.0000e-04\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1450 - acc: 0.9987 - val_loss: 0.9389 - val_acc: 0.8391 - lr: 8.0000e-04\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1453 - acc: 0.9992 - val_loss: 0.9369 - val_acc: 0.8391 - lr: 8.0000e-04\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1440 - acc: 0.9995 - val_loss: 0.9071 - val_acc: 0.8412 - lr: 8.0000e-04\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1439 - acc: 0.9995 - val_loss: 0.9119 - val_acc: 0.8396 - lr: 8.0000e-04\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1435 - acc: 1.0000 - val_loss: 0.9001 - val_acc: 0.8385 - lr: 8.0000e-04\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1442 - acc: 0.9995 - val_loss: 0.9123 - val_acc: 0.8438 - lr: 8.0000e-04\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1441 - acc: 0.9989 - val_loss: 0.9191 - val_acc: 0.8401 - lr: 8.0000e-04\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1446 - acc: 0.9992 - val_loss: 0.9358 - val_acc: 0.8401 - lr: 8.0000e-04\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.1435 - acc: 0.9997 - val_loss: 0.9266 - val_acc: 0.8417 - lr: 8.0000e-04\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1446 - acc: 0.9989 - val_loss: 0.9423 - val_acc: 0.8401 - lr: 8.0000e-04\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.1457 - acc: 0.9984 - val_loss: 0.9465 - val_acc: 0.8375 - lr: 8.0000e-04\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1439 - acc: 0.9992 - val_loss: 0.9424 - val_acc: 0.8401 - lr: 8.0000e-04\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1431 - acc: 1.0000 - val_loss: 0.9337 - val_acc: 0.8396 - lr: 8.0000e-04\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1430 - acc: 0.9997 - val_loss: 0.9308 - val_acc: 0.8370 - lr: 8.0000e-04\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.1439 - acc: 0.9995 - val_loss: 0.9276 - val_acc: 0.8375 - lr: 8.0000e-04\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1435 - acc: 0.9997 - val_loss: 0.9299 - val_acc: 0.8359 - lr: 8.0000e-04\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1439 - acc: 0.9995 - val_loss: 0.9341 - val_acc: 0.8385 - lr: 8.0000e-04\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1432 - acc: 0.9995 - val_loss: 0.9576 - val_acc: 0.8348 - lr: 8.0000e-04\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1442 - acc: 0.9995 - val_loss: 0.9214 - val_acc: 0.8380 - lr: 8.0000e-04\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1435 - acc: 0.9995 - val_loss: 0.9527 - val_acc: 0.8359 - lr: 8.0000e-04\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1425 - acc: 0.9997 - val_loss: 0.9202 - val_acc: 0.8375 - lr: 8.0000e-04\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1433 - acc: 0.9997 - val_loss: 0.9141 - val_acc: 0.8364 - lr: 8.0000e-04\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1426 - acc: 0.9995 - val_loss: 0.9161 - val_acc: 0.8375 - lr: 8.0000e-04\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1426 - acc: 0.9995 - val_loss: 0.9205 - val_acc: 0.8375 - lr: 8.0000e-04\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1443 - acc: 0.9989 - val_loss: 0.9374 - val_acc: 0.8370 - lr: 8.0000e-04\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1429 - acc: 0.9995 - val_loss: 0.9257 - val_acc: 0.8370 - lr: 8.0000e-04\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1423 - acc: 0.9992 - val_loss: 0.9167 - val_acc: 0.8422 - lr: 8.0000e-04\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1439 - acc: 0.9995 - val_loss: 0.9301 - val_acc: 0.8364 - lr: 8.0000e-04\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1432 - acc: 0.9989 - val_loss: 0.9035 - val_acc: 0.8422 - lr: 8.0000e-04\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1437 - acc: 0.9992 - val_loss: 0.9605 - val_acc: 0.8385 - lr: 8.0000e-04\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 0.1429 - acc: 0.9987 - val_loss: 0.9052 - val_acc: 0.8417 - lr: 8.0000e-04\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 15s 511ms/step - loss: 0.1414 - acc: 0.9997 - val_loss: 0.9245 - val_acc: 0.8385 - lr: 8.0000e-04\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 15s 515ms/step - loss: 0.1428 - acc: 0.9997 - val_loss: 0.9047 - val_acc: 0.8380 - lr: 8.0000e-04\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 15s 513ms/step - loss: 0.1422 - acc: 0.9997 - val_loss: 0.8994 - val_acc: 0.8385 - lr: 8.0000e-04\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 15s 514ms/step - loss: 0.1426 - acc: 0.9989 - val_loss: 0.9231 - val_acc: 0.8412 - lr: 8.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-QerZ4RN91R",
        "colab_type": "code",
        "outputId": "c138019c-b314-4e86-f9a4-a33195b3c351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import  pyplot\n",
        "\n",
        "\n",
        "pyplot.plot(hist.history[\"acc\"], label='train')\n",
        "pyplot.plot(hist.history['val_acc'], label='test')\n",
        "pyplot.savefig(\"deneme.png\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeg6MBf-GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_err = [1.0-x for x in hist.history['val_acc']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgiKT6i5GiJ9",
        "colab_type": "code",
        "outputId": "5a5d1d9b-a4e8-406b-a51f-0b882d6a0dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "pyplot.plot(test_err, label='test')\n",
        "pyplot.savefig(\"deneme_err.png\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-IJ9Z-dQKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "wrn_28_10.save(\"parseval_tensor_lst.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqddlwbmEV9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = wrn_28_10.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDVf4J_lEb2R",
        "colab_type": "code",
        "outputId": "5bdc07a1-9e1e-4ec5-d5f6-0d848eae9206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred[8]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.1024935e-02, 9.7708249e-01, 1.3594669e-03, 5.3310243e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mcYkI-REb63",
        "colab_type": "code",
        "outputId": "17a7ea63-28ac-43cb-f3cb-f95257d90478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(y_pred[8])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9Ysop6NFDbs",
        "colab_type": "code",
        "outputId": "0e11a8f2-4a2f-446d-ff19-3ba7f4428b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "wrn_28_10.evaluate(X_test,to_categorical(y_test_df['New']),batch_size=128,verbose=2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 - 2s - loss: 0.9231 - acc: 0.8412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9231326580047607, 0.8411858081817627]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfXeT5NJFmUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d025b38-52c6-4ffa-f1b8-ea190179a779"
      },
      "source": [
        "y_test_df['New'][8]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxKfbFgo05j0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THYCAlBW15Kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "293bdb34-113d-4a78-d934-0e669ebdf442"
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     || 87.9MB 35kB/s \n",
            "\u001b[K     || 501kB 39.0MB/s \n",
            "\u001b[K     || 3.1MB 44.9MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-wgp3ajip/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-wgp3ajip/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     || 163kB 2.8MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     || 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.4)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.15.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=9b140e898b4fd588b7d61044063a489b678633c8bb1e1e90c30e9ec89fb65772\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g87wshp1/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n",
            "\n",
            "Tensorflow Version: 2.2.0\n",
            "Cleverhans Version: 3.0.1-fc7b7c7ec903258e0e3fb88503fa629f\n",
            "WARNING:tensorflow:From <ipython-input-45-67a2c783edbc>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNev4Y9U2sFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(wrn_28_10.input,wrn_28_10.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtKEw7Uq3Dj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_index = np.random.randint(X_test.shape[0])\n",
        "\n",
        "original_image = X_test[random_index]\n",
        "original_image = tf.convert_to_tensor(original_image.reshape((1,68,100))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdxYTfSn3R4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaa38937-ae76-4b12-ede5-ef8310fabf11"
      },
      "source": [
        "original_image.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 68, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSa4WKy33U3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2cde0384-1f71-4ad2-a584-fcb253af55f1"
      },
      "source": [
        "wrn_28_10(original_image)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
              "array([[3.5369150e-02, 9.6226656e-01, 2.2395258e-03, 1.2480342e-04]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jrP3jw83fwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_cat = to_categorical(y_test_df['New'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VoJsNJX4HiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb9cea88-6240-46c2-9cc2-6dc0dcd1b323"
      },
      "source": [
        "original_label = y_test_cat[random_index]\n",
        "original_label "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70kNexu3l-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.33\n",
        "\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "adv_example_untargeted_label_pred = wrn_28_10.predict(adv_example_untargeted_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-LglBmM4gNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "86e28cf3-6eb8-4857-af08-eefcdc9447e0"
      },
      "source": [
        "adv_example_untargeted_label"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 68, 100), dtype=float32, numpy=\n",
              "array([[[ 2.2472608 ,  2.0218558 ,  2.066937  , ..., -1.5233265 ,\n",
              "         -1.2528406 , -0.5928407 ],\n",
              "        [ 2.2472608 ,  2.0218558 ,  2.066937  , ..., -1.3430027 ,\n",
              "         -1.3880836 , -1.3880836 ],\n",
              "        [ 1.5872607 ,  1.4520178 ,  1.4520178 , ..., -1.5684075 ,\n",
              "         -1.4331646 , -1.4331646 ],\n",
              "        ...,\n",
              "        [ 1.5421798 ,  1.976775  ,  1.976775  , ..., -0.86332643,\n",
              "         -0.8182454 , -0.5928407 ],\n",
              "        [ 1.5421798 ,  1.3618559 ,  2.0218558 , ..., -0.8182454 ,\n",
              "         -0.7731645 , -0.6379216 ],\n",
              "        [ 1.2266129 ,  1.271694  ,  1.271694  , ..., -0.8182454 ,\n",
              "         -0.6379216 , -0.6830026 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d6rZhTp4i2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "661a7a6b-0e1b-4669-bef3-480acb1b3c9d"
      },
      "source": [
        "np.argmax(adv_example_untargeted_label_pred)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}